 that task neural
network could be feedforward or recurrent, the overall system is a recurrent network.
The task network can choose to read from or write to speciï¬?c memory addresses.
Explicit memory seems to allow models to learn tasks that ordinary RNNs or LSTM
RNNs cannot learn. One reason for this advantage may be because information and
gradients can be propagated (forward in time or backwards in time, respectively)
for very long durations.
As an alternative to back-propagation through weighted averages of memory
cells, we can interpret the memory addressing coeï¬ƒcients as probabilities and
stochastically read just one cell (Zaremba and Sutskever, 2015). Optimizing models
that make discrete decisions requires specialized optimization algorithms, described
in section 20.9.1. So far, training these stochastic architectures that make discrete
decisions remains harder than training deterministic algorithms that make soft
decisions.
Whether it is soft (allowing back-propagation) or stochastic and hard, the
419

CHAPTER 10. SEQUENCE MODELING: RECURRENT AND RECURSIVE NETS

mechanism for choosing an address is in its form identical to the attention
mechanism which had been previously introduced in the context of machine
translation (Bahdanau et al., 2015) and discussed in section 12.4.5.1. The idea
of attention mechanisms for neural networks was introduced even earlier, in the
context of handwriting generation (Graves, 2013), with an attention mechanism
that was constrained to move only forward in time through the sequence. In
the case of machine translation and memory networks, at each step, the focus of
attention can move to a completely diï¬€erent place, compared to the previous step.
Recurrent neural networks provide a way to extend deep learning to sequential
data. They are the last major tool in our deep learning toolbox. Our discussion now
moves to how to choose and use these tools and how to apply them to real-world
tasks.

420

Chapter 11

Practical Methodology
Successfully applying deep learning techniques requires more than just a good
knowledge of what algorithms exist and the principles that explain how they
work. A good machine learning practitioner also needs to know how to choose an
algorithm for a particular application and how to monitor and respond to feedback
obtained from experiments in order to improve a machine learning system. During
day to day development of machine learning systems, practitioners need to decide
whether to gather more data, increase or decrease model capacity, add or remove
regularizing features, improve the optimization of a model, improve approximate
inference in a model, or debug the software implementation of the model. All of
these operations are at the very least time-consuming to try out, so it is important
to be able to determine the right course of action rather than blindly guessing.
Most of this book is about diï¬€erent machine learning models, training algorithms, and objective functions. This may give the impression that the most
important ingredient to being a machine learning expert is knowing a wide variety
of machine learning techniques and being good at diï¬€erent kinds of math. In practice, one can usually do much better with a correct application of a commonplace
algorithm than by sloppily applying an obscure algorithm. Correct application of
an algorithm depends on mastering some fairly simple methodology. Many of the
recommendations in this chapter are adapted from Ng (2015).
We recommend the following practical design process:
â€¢ Determine your goalsâ€”what error metric to use, and your target value for
this error metric. These goals and error metrics should be driven by the
problem that the application is intended to solve.
â€¢ Establish a working end-to-end pipeline as soon as possible, including the
421

CHAPTER 11. PRACTICAL METHODOLOGY

estimation of the appropriate performance metrics.
â€¢ Instrument the system well to determine bottlenecks in performance. Diagnose which components are performing worse than expected and whether it
is due to overï¬?tting, underï¬?tting, or a defect in the data or software.
â€¢ Repeatedly make incremental changes such as gathering new data, adjusting
hyperparameters, or changing algorithms, based on speciï¬?c ï¬?ndings from
your instrumentation.
As a running example, we will use Street View address number transcription
system (Goodfellow et al., 2014d). The purpose of this application is to add
buildings to Google Maps. Street View cars photograph the buildings and record
the GPS coordinates associated with each photograph. A convolutional network
recognizes the address number in each photograph, allowing the Google Maps
database to add that address in the correct location. The story of how this
commercial application was developed gives an example of how to follow the design
methodology we advocate.
We now describe each of the steps in this process.

11.1

Performance Metrics

Determining your goals, in terms of which error metric to use, is a necessary ï¬?rst
step because your error metric will guide all of your future actions. You should
also have an idea of what level of performance you desire.
Keep in mind that for most applications, it is impossible to achieve absolute
zero error. The Bayes error deï¬?nes the minimum error rate that you can hope to
achieve, even if you have inï¬?nite training data and can recover the true probability
distribution. This is because your input features may not contain complete
information about the output variable, or because the system might be intrinsically
stochastic. You will also be limited by having a ï¬?nite amount of training data.
The amount of training data can be limited for a variety of reasons. When your
goal is to build the best possible real-world product or service, you can typically
collect more data but must determine the value of reducing error further and weigh
this against the cost of collecting more data. Data collection can require time,
money, or human suï¬€ering (for example, if your data collection process involves
performing invasive medical tests). When your goal is to answer a scientiï¬?c question
about which algorithm performs better on a ï¬?xed benchmark, the benchmark
422

CHAPTER 11. PRACTICAL METHODOLOGY

speciï¬?cation usually determines the training set and you are not allowed to collect
more data.
How can one determine a reasonable level of performance to expect? Typically,
in the academic setting, we have some estimate of the error rate that is attainable
based on previously published benchmark results. In the real-word setting, we
have some idea of the error rate that is necessary for an application to be safe,
cost-eï¬€ective, or appealing to consumers. Once you have determined your realistic
desired error rate, your design decisions will be guided by reaching this error rate.
Another important consideration besides the target value of the performance
metric is the choice of which metric to use. Several diï¬€erent performance metrics
may be used to measure the eï¬€ectiveness of a complete application that includes
machine learning components. These performance metrics are usually diï¬€erent
from the cost function used to train the model. As described in section 5.1.2, it is
common to measure the accuracy, or equivalently, the error rate, of a system.
However, many applications require more advanced metrics.
Sometimes it is much more costly to make one kind of a mistake than another.
For example, an e-mail spam detection system can make two kinds of mistakes:
incorrectly classifying a legitimate message as spam, and incorrectly allowing a
spam message to appear in the inbox. It is much worse to block a legitimate
message than to allow a questionable message to pass through. Rather than
measuring the error rate of a spam classiï¬?er, we may wish to measure some form
of total cost, where the cost of blocking legitimate messages is higher than the cost
of allowing spam messages.
Sometimes we wish to train a binary classiï¬?er that is intended to detect some
rare event. For example, we might design a medical test for a rare disease. Suppose
that only one in every million people has this disease. We can easily achieve
99.9999% accuracy on the detection task, by simply hard-coding the classiï¬?er
to always report that the disease is absent. Clearly, accuracy is a poor way to
characterize the performance of such a system. One way to solve this problem is
to instead measure precision and recall. Precision is the fraction of detections
reported by the model that were correct, while recall is the fraction of true events
that were detected. A detector that says no one has the disease would achieve
perfect precision, but zero recall. A detector that says everyone has the disease
would achieve perfect recall, but precision equal to the percentage of people who
have the disease (0.0001% in our example of a disease that only one people in a
million have). When using precision and recall, it is common to plot a PR curve,
with precision on the y-axis and recall on the x-axis. The classiï¬?er generates a score
that is higher if the event to be detected occurred. For example, a feedforward
423

CHAPTER 11. PRACTICAL METHODOLOGY

network designed to detect a disease outputs yÌ‚ = P (y = 1 | x), estimating the
probability that a person whose medical results are described by features x has
the disease. We choose to report a detection whenever this score exceeds some
threshold. By varying the threshold, we can trade precision for recall. In many
cases, we wish to summarize the performance of the classiï¬?er with a single number
rather than a curve. To do so, we can convert precision p and recall r into an
F-score given by
2pr
F =
.
(11.1)
p+r
Another option is to report the total area lying beneath the PR curve.
In some applications, it is possible for the machine learning system to refuse to
make a decision. This is useful when the machine learning algorithm can estimate
how conï¬?dent it should be about a decision, especially if a wrong decision can
be harmful and if a human operator is able to occasionally take over. The Street
View transcription system provides an example of this situation. The task is to
transcribe the address number from a photograph in order to associate the location
where the photo was taken with the correct address in a map. Because the value
of the map degrades considerably if the map is inaccurate, it is important to add
an address only if the transcription is correct. If the machine learning system
thinks that it is less likely than a human being to obtain the correct transcription,
then the best course of action is to allow a human to transcribe the photo instead.
Of course, the machine learning system is only useful if it is able to dramatically
reduce the amount of photos that the human operators must process. A natural
performance metric to use in this situation is coverage. Coverage is the fraction
of examples for which the machine learning system is able to produce a response.
It is possible to trade coverage for accuracy. One can always obtain 100% accuracy
by refusing to process any example, but this reduces the coverage to 0%. For the
Street View task, the goal for the project was to reach human-level transcription
accuracy while maintaining 95% coverage. Human-level performance on this task
is 98% accuracy.
Many other metrics are possible. We can for example, measure click-through
rates, collect user satisfaction surveys, and so on. Many specialized application
areas have application-speciï¬?c criteria as well.
What is important is to determine which performance metric to improve ahead
of time, then concentrate on improving this metric. Without clearly deï¬?ned goals,
it can be diï¬ƒcult to tell whether changes to a machine learning system make
progress or not.

424

CHAPTER 11. PRACTICAL METHODOLOGY

11.2

Default Baseline Models

After choosing performance metrics and goals, the next step in any practical
application is to establish a reasonable end-to-end system as soon as possible. In
this section, we provide recommendations for which algorithms to use as the ï¬?rst
baseline approach in various situations. Keep in mind that deep learning research
progresses quickly, so better default algorithms are likely to become available soon
after this writing.
Depending on the complexity of your problem, you may even want to begin
without using deep learning. If your problem has a chance of being solved by
just choosing a few linear weights correctly, you may want to begin with a simple
statistical model like logistic regression.
If you know that your problem falls into an â€œAI-completeâ€? category like object
recognition, speech recognition, machine translation, and so on, then you are likely
to do well by beginning with an appropriate deep learning model.
First, choose the general category of model based on the structure of your
data. If you want to perform supervised learning with ï¬?xed-size vectors as input,
use a feedforward network with fully connected layers. If the input has known
topological structure (for example, if the input is an image), use a convolutional
network. In these cases, you should begin by using some kind of piecewise linear
unit (ReLUs or their generalizations like Leaky ReLUs, PreLus and maxout). If
your input or output is a sequence, use a gated recurrent net (LSTM or GRU).
A reasonable choice of optimization algorithm is SGD with momentum with a
decaying learning rate (popular decay schemes that perform better or worse on
diï¬€erent problems include decaying linearly until reaching a ï¬?xed minimum learning
rate, decaying exponentially, or decreasing the learning rate by a factor of 2-10
each time validation error plateaus). Another very reasonable alternative is Adam.
Batch normalization can have a dramatic eï¬€ect on optimization performance,
especially for convolutional networks and networks with sigmoidal nonlinearities.
While it is reasonable to omit batch normalization from the very ï¬?rst baseline, it
should be introduced quickly if optimization appears to be problematic.
Unless your training set contains tens of millions of examples or more, you
should include some mild forms of regularization from the start. Early stopping
should be used almost universally. Dropout is an excellent regularizer that is easy
to implement and compatible with many models and training algorithms. Batch
normalization also sometimes reduces generalization error and allows dropout to
be omitted, due to the noise in the estimate of the statistics used to normalize
each variable.
425

CHAPTER 11. PRACTICAL METHODOLOGY

If your task is similar to another task that has been studied extensively, you
will probably do well by ï¬?rst copying the model and algorithm that is already
known to perform best on the previously studied task. You may even want to copy
a trained model from that task. For example, it is common to use the features
from a convolutional network trained on ImageNet to solve other computer vision
tasks (Girshick et al., 2015).
A common question is whether to begin by using unsupervised learning, described further in part III. This is somewhat domain speciï¬?c. Some domains, such
as natural language processing, are known to beneï¬?t tremendously from unsupervised learning techniques such as learning unsupervised word embeddings. In other
domains, such as computer vision, current unsupervised lea