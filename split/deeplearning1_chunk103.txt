
1
p model (x, z )
.
(20.79)
L k (x, q) = Ez(1),...,z(k) âˆ¼q(z |x) log
k i=1 q(z (i) | x)
This new objective is equivalent to the traditional lower bound L when k = 1.
However, it may also be interpreted as forming an estimate of the true log p model(x)
using importance sampling of z from proposal distribution q( z | x). The importance
weighted autoencoder objective is also a lower bound on log pmodel (x) and becomes
tighter as k increases.
Variational autoencoders have some interesting connections to the MP-DBM
and other approaches that involve back-propagation through the approximate
inference graph (Goodfellow et al., 2013b; Stoyanov et al., 2011; Brakel et al., 2013).
These previous approaches required an inference procedure such as mean ï¬?eld ï¬?xed
point equations to provide the computational graph. The variational autoencoder
is deï¬?ned for arbitrary computational graphs, which makes it applicable to a wider
range of probabilistic model families because there is no need to restrict the choice
698

CHAPTER 20. DEEP GENERATIVE MODELS

of models to those with tractable mean ï¬?eld ï¬?xed point equations. The variational
autoencoder also has the advantage that it increases a bound on the log-likelihood
of the model, while the criteria for the MP-DBM and related models are more
heuristic and have little probabilistic interpretation beyond making the results of
approximate inference accurate. One disadvantage of the variational autoencoder
is that it learns an inference network for only one problem, inferring z given x.
The older methods are able to perform approximate inference over any subset of
variables given any other subset of variables, because the mean ï¬?eld ï¬?xed point
equations specify how to share parameters between the computational graphs for
all of these diï¬€erent problems.
One very nice property of the variational autoencoder is that simultaneously
training a parametric encoder in combination with the generator network forces the
model to learn a predictable coordinate system that the encoder can capture. This
makes it an excellent manifold learning algorithm. See ï¬?gure 20.6 for examples of
low-dimensional manifolds learned by the variational autoencoder. In one of the
cases demonstrated in the ï¬?gure, the algorithm discovered two independent factors
of variation present in images of faces: angle of rotation and emotional expression.

20.10.4

Generative Adversarial Networks

Generative adversarial networks or GANs (Goodfellow et al., 2014c) are another
generative modeling approach based on diï¬€erentiable generator networks.
Generative adversarial networks are based on a game theoretic scenario in
which the generator network must compete against an adversary. The generator
network directly produces samples x = g(z; Î¸ (g ) ). Its adversary, the discriminator
network, attempts to distinguish between samples drawn from the training data
and samples drawn from the generator. The discriminator emits a probability value
given by d(x; Î¸(d)), indicating the probability that x is a real training example
rather than a fake sample drawn from the model.
The simplest way to formulate learning in generative adversarial networks is
as a zero-sum game, in which a function v(Î¸(g ) , Î¸(d)) determines the payoï¬€ of the
discriminator. The generator receives âˆ’v(Î¸ (g ), Î¸(d)) as its own payoï¬€. During
learning, each player attempts to maximize its own payoï¬€, so that at convergence
gâˆ— = arg min max v(g, d).
d

g

(20.80)

The default choice for v is
v(Î¸ (g ), Î¸(d) ) = Exâˆ¼p data log d(x) + E xâˆ¼pmodel log (1 âˆ’ d(x)) .
699

(20.81)

CHAPTER 20. DEEP GENERATIVE MODELS

Figure 20.6: Examples of two-dimensional coordinate systems for high-dimensional manifolds, learned by a variational autoencoder (Kingma and Welling, 2014a). Two dimensions
may be plotted directly on the page for visualization, so we can gain an understanding of
how the model works by training a model with a 2-D latent code, even if we believe the
intrinsic dimensionality of the data manifold is much higher. The images shown are not
examples from the training set but images x actually generated by the model p( x | z),
simply by changing the 2-D â€œcodeâ€? z (each image corresponds to a diï¬€erent choice of â€œcodeâ€?
z on a 2-D uniform grid). (Left)The two-dimensional map of the Frey faces manifold.
One dimension that has been discovered (horizontal) mostly corresponds to a rotation of
the face, while the other (vertical) corresponds to the emotional expression. (Right)The
two-dimensional map of the MNIST manifold.

This drives the discriminator to attempt to learn to correctly classify samples as real
or fake. Simultaneously, the generator attempts to fool the classiï¬?er into believing
its samples are real. At convergence, the generatorâ€™s samples are indistinguishable
from real data, and the discriminator outputs 12 everywhere. The discriminator
may then be discarded.
The main motivation for the design of GANs is that the learning process
requires neither approximate inference nor approximation of a partition function
gradient. In the case where maxd v(g, d) is convex in Î¸(g ) (such as the case where
optimization is performed directly in the space of probability density functions)
the procedure is guaranteed to converge and is asymptotically consistent.
Unfortunately, learning in GANs can be diï¬ƒcult in practice when g and d
are represented by neural networks and max d v(g, d) is not convex. Goodfellow
700

CHAPTER 20. DEEP GENERATIVE MODELS

(2014) identiï¬?ed non-convergence as an issue that may cause GANs to underï¬?t.
In general, simultaneous gradient descent on two playersâ€™ costs is not guaranteed
to reach an equilibrium. Consider for example the value function v(a, b) = ab,
where one player controls a and incurs cost ab, while the other player controls b
and receives a cost âˆ’ab. If we model each player as making inï¬?nitesimally small
gradient steps, each player reducing their own cost at the expense of the other
player, then a and b go into a stable, circular orbit, rather than arriving at the
equilibrium point at the origin. Note that the equilibria for a minimax game are
not local minima of v. Instead, they are points that are simultaneously minima
for both playersâ€™ costs. This means that they are saddle points of v that are local
minima with respect to the ï¬?rst playerâ€™s parameters and local maxima with respect
to the second playerâ€™s parameters. It is possible for the two players to take turns
increasing then decreasing v forever, rather than landing exactly on the saddle
point where neither player is capable of reducing its cost. It is not known to what
extent this non-convergence problem aï¬€ects GANs.
Goodfellow (2014) identiï¬?ed an alternative formulation of the payoï¬€s, in which
the game is no longer zero-sum, that has the same expected gradient as maximum
likelihood learning whenever the discriminator is optimal. Because maximum
likelihood training converges, this reformulation of the GAN game should also
converge, given enough samples. Unfortunately, this alternative formulation does
not seem to improve convergence in practice, possibly due to suboptimality of the
discriminator, or possibly due to high variance around the expected gradient.
In realistic experiments, the best-performing formulation of the GAN game
is a diï¬€erent formulation that is neither zero-sum nor equivalent to maximum
likelihood, introduced by Goodfellow et al. (2014c) with a heuristic motivation. In
this best-performing formulation, the generator aims to increase the log probability
that the discriminator makes a mistake, rather than aiming to decrease the log
probability that the discriminator makes the correct prediction. This reformulation
is motivated solely by the observation that it causes the derivative of the generatorâ€™s
cost function with respect to the discriminatorâ€™s logits to remain large even in the
situation where the discriminator conï¬?dently rejects all generator samples.
Stabilization of GAN learning remains an open problem. Fortunately, GAN
learning performs well when the model architecture and hyperparameters are carefully selected. Radford et al. (2015) crafted a deep convolutional GAN (DCGAN)
that performs very well for image synthesis tasks, and showed that its latent representation space captures important factors of variation, as shown in ï¬?gure 15.9.
See ï¬?gure 20.7 for examples of images generated by a DCGAN generator.
The GAN learning problem can also be simpliï¬?ed by breaking the generation
701

CHAPTER 20. DEEP GENERATIVE MODELS

Figure 20.7: Images generated by GANs trained on the LSUN dataset. (Left)Images
of bedrooms generated by a DCGAN model, reproduced with permission from Radford
et al. (2015). (Right)Images of churches generated by a LAPGAN model, reproduced with
permission from Denton et al. (2015).

process into many levels of detail. It is possible to train conditional GANs (Mirza
and Osindero, 2014) that learn to sample from a distribution p(x | y ) rather
than simply sampling from a marginal distribution p(x). Denton et al. (2015)
showed that a series of conditional GANs can be trained to ï¬?rst generate a very
low-resolution version of an image, then incrementally add details to the image.
This technique is called the LAPGAN model, due to the use of a Laplacian pyramid
to generate the images containing varying levels of detail. LAPGAN generators
are able to fool not only discriminator networks but also human observers, with
experimental subjects identifying up to 40% of the outputs of the network as
being real data. See ï¬?gure 20.7 for examples of images generated by a LAPGAN
generator.
One unusual capability of the GAN training procedure is that it can ï¬?t probability distributions that assign zero probability to the training points. Rather than
maximizing the log probability of speciï¬?c points, the generator net learns to trace
out a manifold whose points resemble training points in some way. Somewhat paradoxically, this means that the model may assign a log-likelihood of negative inï¬?nity
to the test set, while still representing a manifold that a human observer judges
to capture the essence of the generation task. This is not clearly an advantage or
a disadvantage, and one may also guarantee that the generator network assigns
non-zero probability to all points simply by making the last layer of the generator
network add Gaussian noise to all of the generated values. Generator networks
that add Gaussian noise in this manner sample from the same distribution that one
obtains by using the generator network to parametrize the mean of a conditional
702

CHAPTER 20. DEEP GENERATIVE MODELS

Gaussian distribution.
Dropout seems to be important in the discriminator network. In particular,
units should be stochastically dropped while computing the gradient for the
generator network to follow. Following the gradient of the deterministic version of
the discriminator with its weights divided by two does not seem to be as eï¬€ective.
Likewise, never using dropout seems to yield poor results.
While the GAN framework is designed for diï¬€erentiable generator networks,
similar principles can be used to train other kinds of models. For example, selfsupervised boosting can be used to train an RBM generator to fool a logistic
regression discriminator (Welling et al., 2002).

20.10.5

Generative Moment Matching Networks

Generative moment matching networks (Li et al., 2015; Dziugaite et al.,
2015) are another form of generative model based on diï¬€erentiable generator
networks. Unlike VAEs and GANs, they do not need to pair the generator network
with any other networkâ€”neither an inference network as used with VAEs nor a
discriminator network as used with GANs.
These networks are trained with a technique called moment matching. The
basic idea behind moment matching is to train the generator in such a way that
many of the statistics of samples generated by the model are as similar as possible
to those of the statistics of the examples in the training set. In this context, a
moment is an expectation of diï¬€erent powers of a random variable. For example,
the ï¬?rst moment is the mean, the second moment is the mean of the squared
values, and so on. In multiple dimensions, each element of the random vector may
be raised to diï¬€erent powers, so that a moment may be any quantity of the form
Ex Î i xni i

(20.82)

where n = [n 1, n 2, . . . , nd]î€¾ is a vector of non-negative integers.
Upon ï¬?rst examination, this approach seems to be computationally infeasible.
For example, if we want to match all the moments of the form xix j , then we need
to minimize the diï¬€erence between a number of values that is quadratic in the
dimension of x. Moreover, even matching all of the ï¬?rst and second moments
would only be suï¬ƒcient to ï¬?t a multivariate Gaussian distribution, which captures
only linear relationships between values. Our ambitions for neural networks are to
capture complex nonlinear relationships, which would require far more moments.
GANs avoid this problem of exhaustively enumerating all moments by using a
703

CHAPTER 20. DEEP GENERATIVE MODELS

dynamically updated discriminator that automatically focuses its attention on
whichever statistic the generator network is matching the least eï¬€ectively.
Instead, generative moment matching networks can be trained by minimizing
a cost function called maximum mean discrepancy (SchÃ¶lkopf and Smola,
2002; Gretton et al., 2012) or MMD. This cost function measures the error in
the ï¬?rst moments in an inï¬?nite-dimensional space, using an implicit mapping
to feature space deï¬?ned by a kernel function in order to make computations on
inï¬?nite-dimensional vectors tractable. The MMD cost is zero if and only if the two
distributions being compared are equal.
Visually, the samples from generative moment matching networks are somewhat
disappointing. Fortunately, they can be improved by combining the generator
network with an autoencoder. First, an autoencoder is trained to reconstruct the
training set. Next, the encoder of the autoencoder is used to transform the entire
training set into code space. The generator network is then trained to generate
code samples, which may be mapped to visually pleasing samples via the decoder.
Unlike GANs, the cost function is deï¬?ned only with respect to a batch of
examples from both the training set and the generator network. It is not possible
to make a training update as a function of only one training example or only
one sample from the generator network. This is because the moments must be
computed as an empirical average across many samples. When the batch size is too
small, MMD can underestimate the true amount of variation in the distributions
being sampled. No ï¬?nite batch size is suï¬ƒciently large to eliminate this problem
entirely, but larger batches reduce the amount of underestimation. When the batch
size is too large, the training procedure becomes infeasibly slow, because many
examples must be processed in order to compute a single small gradient step.
As with GANs, it is possible to train a generator net using MMD even if that
generator net assigns zero probability to the training points.

20.10.6

Convolutional Generative Networks

When generating images, it is often useful to use a generator network that includes
a convolutional structure (see for example Goodfellow et al. (20