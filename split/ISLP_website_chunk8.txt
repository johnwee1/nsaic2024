o repBoolean
resented as 1 and 0, respectively). The next line creates a vector of 0’s,
represented as Booleans, of length equal to the first dimension of A.
In [66]: keep_rows = np.zeros(A.shape [0], bool)
keep_rows
Out[66]: array ([False ,

False , False ,

False ])

We now set two of the elements to True.
In [67]: keep_rows [[1 ,3]] = True
keep_rows

54

2. Statistical Learning

Out[67]: array ([False ,

True , False ,

True ])

Note that the elements of keep_rows, when viewed as integers, are the same
as the values of np.array([0,1,0,1]). Below, we use == to verify their equality. When applied to two arrays, the == operation is applied elementwise.
In [68]: np.all(keep_rows == np.array ([0 ,1 ,0 ,1]))
Out[68]: True

(Here, the function np.all() has checked whether all entries of an array
np.all()
are True. A similar function, np.any(), can be used to check whether any
np.any()
entries of an array are True.)
However, even though np.array([0,1,0,1]) and keep_rows are equal according to ==, they index different sets of rows! The former retrieves the
first, second, first, and second rows of A.
In [69]: A[np.array ([0 ,1 ,0 ,1])]
Out[69]: array ([[0, 1, 2, 3],
[4, 5, 6, 7],
[0, 1, 2, 3],
[4, 5, 6, 7]])

By contrast, keep_rows retrieves only the second and fourth rows of A —
i.e. the rows for which the Boolean equals TRUE.
In [70]: A[keep_rows]
Out[70]: array ([[ 4, 5, 6, 7],
[12, 13, 14, 15]])

This example shows that Booleans and integers are treated differently by
numpy.
We again make use of the np.ix_() function to create a mesh containing
the second and fourth rows, and the first, third, and fourth columns. This
time, we apply the function to Booleans, rather than lists.
In [71]: keep_cols = np.zeros(A.shape [1], bool)
keep_cols [[0, 2, 3]] = True
idx_bool = np.ix_(keep_rows , keep_cols)
A[idx_bool]
Out[71]: array ([[ 4, 6, 7],
[12, 14, 15]])

We can also mix a list with an array of Booleans in the arguments to
np.ix_():
In [72]: idx_mixed = np.ix_ ([1,3], keep_cols)
A[idx_mixed]
Out[72]: array ([[ 4, 6, 7],
[12, 14, 15]])

For more details on indexing in numpy, readers are referred to the numpy
tutorial mentioned earlier.

2.3 Lab: Introduction to Python

2.3.7

55

Loading Data

Data sets often contain different types of data, and may have names associated with the rows or columns. For these reasons, they typically are
best accommodated using a data frame. We can think of a data frame as
data frame
a sequence of arrays of identical length; these are the columns. Entries in
the different arrays can be combined to form a row. The pandas library can
be used to create and work with data frame objects.
Reading in a Data Set
The first step of most analyses involves importing a data set into Python.
Before attempting to load a data set, we must make sure that Python knows
where to find the file containing it. If the file is in the same location as this
notebook file, then we are all set. Otherwise, the command os.chdir() can
os.chdir()
be used to change directory. (You will need to call import os before calling
os.chdir().)
We will begin by reading in Auto.csv, available on the book website. This
is a comma-separated file, and can be read in using pd.read_csv():

pd.read_csv()

In [73]: import pandas as pd
Auto = pd.read_csv('Auto.csv')
Auto

The book website also has a whitespace-delimited version of this data,
called Auto.data. This can be read in as follows:
In [74]: Auto = pd.read_csv('Auto.data ', delim_whitespace=True)

Both Auto.csv and Auto.data are simply text files. Before loading data into
Python, it is a good idea to view it using a text editor or other software,
such as Microsoft Excel.
We now take a look at the column of Auto corresponding to the variable
horsepower:
In [75]: Auto['horsepower ']
Out[75]: 0
1
2
3
4

130.0
165.0
150.0
150.0
140.0
...
392
86.00
393
52.00
394
84.00
395
79.00
396
82.00
Name: horsepower , Length: 397, dtype: object

We see that the dtype of this column is object. It turns out that all values
of the horsepower column were interpreted as strings when reading in the
data. We can find out why by looking at the unique values.
In [76]: np.unique(Auto['horsepower '])

56

2. Statistical Learning

To save space, we have omitted the output of the previous code block. We
see the culprit is the value ?, which is being used to encode missing values.
To fix the problem, we must provide pd.read_csv() with an argument
called na_values. Now, each instance of ? in the file is replaced with the
value np.nan, which means not a number:
In [77]: Auto = pd.read_csv('Auto.data ',
na_values =['?'],
delim_whitespace=True)
Auto['horsepower '].sum()
Out[77]: 40952.0

The Auto.shape attribute tells us that the data has 397 observations, or
rows, and nine variables, or columns.
In [78]: Auto.shape
Out[78]: (397, 9)

There are various ways to deal with missing data. In this case, since
only five of the rows contain missing observations, we choose to use the
Auto.dropna() method to simply remove these rows.
In [79]: Auto_new = Auto.dropna ()
Auto_new.shape
Out[79]: (392, 9)

Basics of Selecting Rows and Columns
We can use Auto.columns to check the variable names.
In [80]: Auto = Auto_new # overwrite the previous value
Auto.columns
Out[80]: Index (['mpg', 'cylinders ', 'displacement ', 'horsepower ',
'weight ', 'acceleration ', 'year ', 'origin ', 'name '],
dtype='object ')

Accessing the rows and columns of a data frame is similar, but not identical, to accessing the rows and columns of an array. Recall that the first
argument to the [] method is always applied to the rows of the array. Similarly, passing in a slice to the [] method creates a data frame whose rows
are determined by the slice:
In [81]: Auto [:3]
Out[81]:

0
1
2

mpg
18.0
15.0
18.0

cylinders
8
8
8

displacement
307.0
350.0
318.0

horsepower
130.0
165.0
150.0

weight
3504.0
3693.0
3436.0

Similarly, an array of Booleans can be used to subset the rows:

...
...
...
...

.dropna()

2.3 Lab: Introduction to Python

57

In [82]: idx_80 = Auto['year '] > 80
Auto[idx_80]

However, if we pass in a list of strings to the [] method, then we obtain a
data frame containing the corresponding set of columns.
In [83]: Auto [['mpg', 'horsepower ']]
Out[83]:

mpg
horsepower
0
18.0
130.0
1
15.0
165.0
2
18.0
150.0
16.0
150.0
3
4
17.0
140.0
...
...
...
392
27.0
86.0
393
44.0
52.0
394
32.0
84.0
395
28.0
79.0
396
31.0
82.0
392 rows x 2 columns

Since we did not specify an index column when we loaded our data frame,
the rows are labeled using integers 0 to 396.
In [84]: Auto.index
Out[84]: Int64Index ([

0,
1,
2,
3,
4,
5,
6,
7,
8,
9,
...
387, 388, 389, 390, 391, 392, 393, 394, 395, 396],
dtype='int64 ', length =392)

We can use the set_index() method to re-name the rows using the contents
.set_index()
of Auto['name'].
In [85]: Auto_re = Auto.set_index('name ')
Auto_re
Out[85]:

name
chevrolet chevelle malibu
buick skylark 32
plymouth satellite
amc rebel sst

mpg

cylinders

displacement

...

18.0
15.0
18.0
16.0

8
8
8
8

307.0
350.0
318.0
304.0

...
...
...
...

In [86]: Auto_re.columns
Out[86]: Index (['mpg', 'cylinders ', 'displacement ', 'horsepower ',
'weight ', 'acceleration ', 'year ', 'origin '],
dtype='object ')

We see that the column 'name' is no longer there.
Now that the index has been set to name, we can access rows of the data
frame by name using the loc[] method of Auto:

.loc[]

58

2. Statistical Learning

In [87]: rows = ['amc rebel sst', 'ford torino ']
Auto_re.loc[rows]
Out[87]:

name
amc rebel sst
ford torino

mpg

cylinders

16.0
17.0

8
8

displacement horsepower
304.0
302.0

150.0
140.0

...
...
...

As an alternative to using the index name, we could retrieve the 4th and
5th rows of Auto using the iloc[] method:

.iloc[]

In [88]: Auto_re.iloc [[3 ,4]]

We can also use it to retrieve the 1st, 3rd and and 4th columns of Auto_re:
In [89]: Auto_re.iloc [: ,[0 ,2 ,3]]

We can extract the 4th and 5th rows, as well as the 1st, 3rd and 4th
columns, using a single call to iloc[]:
In [90]: Auto_re.iloc [[3 ,4] ,[0 ,2 ,3]]
Out[90]:

name
amc rebel sst
ford torino

mpg

displacement

horsepower

16.0
17.0

304.0
302.0

150.0
140.0

Index entries need not be unique: there are several cars in the data frame
named ford galaxie 500.
In [91]: Auto_re.loc['ford galaxie 500', ['mpg', 'origin ']]
Out[91]:

name
ford galaxie 500
ford galaxie 500
ford galaxie 500

mpg

origin

15.0
14.0
14.0

1
1
1

More on Selecting Rows and Columns
Suppose now that we want to create a data frame consisting of the weight
and origin of the subset of cars with year greater than 80 — i.e. those
built after 1980. To do this, we first create a Boolean array that indexes
the rows. The loc[] method allows for Boolean entries as well as strings:
In [92]: idx_80 = Auto_re['year '] > 80
Auto_re.loc[idx_80 , ['weight ', 'origin ']]

To do this more concisely, we can use an anonymous function called a

lambda:

In [93]: Auto_re.loc[lambda df: df['year '] > 80, ['weight ', 'origin ']]

The lambda call creates a function that takes a single argument, here df,
and returns df['year']>80. Since it is created inside the loc[] method for

lambda

2.3 Lab: Introduction to Python

59

the dataframe Auto_re, that dataframe will be the argument supplied. As
another example of using a lambda, suppose that we want all cars built after
1980 that achieve greater than 30 miles per gallon:
In [94]: Auto_re.loc[lambda df: (df['year '] > 80) & (df['mpg'] > 30),
['weight ', 'origin ']
]

The symbol & computes an element-wise and operation. As another example, suppose that we want to retrieve all Ford and Datsun cars with
displacement less than 300. We check whether each name entry contains
either the string ford or datsun using the str.contains() method of the .str.
index attribute of of the dataframe:
contains()
In [95]: Auto_re.loc[lambda df: (df['displacement '] < 300)
& (df.index.str.contains('ford ')
| df.index.str.contains('datsun ')),
['weight ', 'origin ']
]

Here, the symbol | computes an element-wise or operation.
In summary, a powerful set of operations is available to index the rows
and columns of data frames. For integer based queries, use the iloc[]
method. For string and Boolean selections, use the loc[] method. For
functional queries that filter rows, use the loc[] method with a function
(typically a lambda) in the rows argument.

2.3.8

For Loops

A for loop is a standard tool in many languages that repeatedly evaluates for
some chunk of code while varying different values inside the code. For
example, suppose we loop over elements of a list and compute their sum.
In [96]: total = 0
for value in [3 ,2 ,19]:
total += value
print('Total is: {0}'.format(total))
Total is: 24

The indented code beneath the line with the for statement is run for each
value in the sequence specified in the for statement. The loop ends either
when the cell ends or when code is indented at the same level as the original
for statement. We see that the final line above which prints the total is
executed only once after the for loop has terminated. Loops can be nested
by additional indentation.
In [97]: total = 0
for value in [2 ,3 ,19]:
for weight in [3, 2, 1]:
total += value * weight
print('Total is: {0}'.format(total))
Total is: 144

60

2. Statistical Learning

Above, we summed over each combination of value and weight. We also
took advantage of the increment notation in Python: the expression a += b
increment
is equivalent to a = a + b. Besides being a convenient notation, this can
save time in computationally heavy tasks in which the intermediate value
of a+b need not be explicitly created.
Perhaps a more common task would be to sum over (value, weight)
pairs. For instance, to compute the average value of a random variable
that takes on possible values 2, 3 or 19 with probability 0.2, 0.3, 0.5 respectively we would compute the weighted sum. Tasks such as this can often be
accomplished using the zip() function that loops over a sequence of tuples.
zip()

In [98]: total = 0
for value , weight in zip ([2,3,19],
[0.2 ,0.3 ,0.5]):
total += weight * value
print('Weighted average is: {0}'.format(total))
Weighted average is: 10.8

String Formatting
In the code chunk above we also printed a string displaying the total.
However, the object total is an integer and not a string. Inserting the
value of something into a string is a common task, made simple using some
of the powerful string formatting tools in Python. Many data cleaning tasks
involve manipulating and programmatically producing strings.
For example we may want to loop over the columns of a data frame
and print the percent missing in each column. Let’s create a data frame
D with columns in which 20% of the entries are missing i.e. set to np.nan. np.nan
We’ll create the values in D from a normal distribution with mean 0 and
variance 1 using rng.standard_normal() and then overwrite some random
entries using rng.choice().
In [99]: rng = np.random.default_rng (1)
A = rng.standard_normal ((127 , 5))
M = rng.choice ([0, np.nan], p=[0.8 ,0.2] , size=A.shape)
A += M
D = pd.DataFrame(A, columns =['food ',
'bar',
'pickle ',
'snack ',
'popcorn '])
D[:3]
Out[99]:

0
1
2

food
bar
pickle
snack
popcorn
0.345584 0.821618 0.330437 -1.303157
NaN
NaN -0.536953 0.581118 0.364572 0.294132
NaN 0.546713
NaN -0.162910 -0.482119

In [100]: for col in D.columns:
template = 'Column "{0}" has {1:.2%} missing values '
print(template.format(col ,
np.isnan(D[col]).mean ()))

2.3 Lab: Introduction to Python

61

Column "food" has 16.54% missing values
Column "bar" has 25.98% missing values
Column "pickle" has 29.13% missing values
Column "snack" has 21.26% missing values
Column "popcorn" has 22.83% missing values

We see that the template.format() method expects two arguments {0} and
{1:.2%}, and the latter includes some formatting information. In particular,
it specifies that the second argument should be expressed as a percent with
two decimal digits.
The reference docs.python.org/3/library/string.html includes many helpful and more complex examples.

2.3.9

Additional Graphical and Numerical Summaries

We can use the ax.plot() or ax.scatter() functions to display the quantitative variables. However, simply typing the variable names will produce
an error message, because Python does not know to look in the Auto data
set for those variables.
In [101]: fig , ax = subplots(figsize =(8, 8))
ax.plot(horsepower , mpg , 'o');
NameError: name 'horsepower ' is not defined

We can address this by accessing the columns directly:
In [102]: fig , ax = subplots(figsize =(8, 8))
ax.plot(Auto['horsepower '], Auto['mpg'], 'o');

Alternatively, we can use the plot() method with the call Auto.plot(). Us.plot()
ing this method, the variables can be accessed by name. The plot methods
of a data frame return a familiar object: an axes. We can use it to update
the plot as we did previously:
In [103]: ax = Auto.plot.scatter('horsepower ', 'mpg');
ax.set_title('Horsepower vs. MPG')

If we want to save the figure that contains a given axes, we can find the
relevant figure by accessing the figure attribute:
In [104]: fig = ax.figure
fig.savefig('horsepower_mpg.png');

We can further instruct the data frame to plot to a particular axes object.
In this case the corresponding plot() method will return the modified axes
we passed in as an argument. Note that when we request a one-dimensional
grid of plots, the object axes is similarly one-dimensional. We place our
scatter plot in the middle plot of a row of