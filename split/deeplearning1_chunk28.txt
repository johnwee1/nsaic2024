er can get by with k times fewer weights.
Because each unit is driven by multiple ï¬?lters, maxout units have some redundancy that helps them to resist a phenomenon called catastrophic forgetting
in which neural networks forget how to perform tasks that they were trained on in
the past (Goodfellow et al., 2014a).
Rectiï¬?ed linear units and all of these generalizations of them are based on the
principle that models are easier to optimize if their behavior is closer to linear.
This same general principle of using linear behavior to obtain easier optimization
also applies in other contexts besides deep linear networks. Recurrent networks can
learn from sequences and produce a sequence of states and outputs. When training
them, one needs to propagate information through several time steps, which is much
easier when some linear computations (with some directional derivatives being of
magnitude near 1) are involved. One of the best-performing recurrent network
194

CHAPTER 6. DEEP FEEDFORWARD NETWORKS

architectures, the LSTM, propagates information through time via summationâ€”a
particular straightforward kind of such linear activation. This is discussed further
in section 10.10.

6.3.2

Logistic Sigmoid and Hyperbolic Tangent

Prior to the introduction of rectiï¬?ed linear units, most neural networks used the
logistic sigmoid activation function
g (z ) = Ïƒ (z )

(6.38)

or the hyperbolic tangent activation function
g (z ) = tanh(z ).

(6.39)

These activation functions are closely related because tanh(z ) = 2Ïƒ (2z ) âˆ’ 1.

We have already seen sigmoid units as output units, used to predict the
probability that a binary variable is 1. Unlike piecewise linear units, sigmoidal
units saturate across most of their domainâ€”they saturate to a high value when
z is very positive, saturate to a low value when z is very negative, and are only
strongly sensitive to their input when z is near 0. The widespread saturation of
sigmoidal units can make gradient-based learning very diï¬ƒcult. For this reason,
their use as hidden units in feedforward networks is now discouraged. Their use
as output units is compatible with the use of gradient-based learning when an
appropriate cost function can undo the saturation of the sigmoid in the output
layer.
When a sigmoidal activation function must be used, the hyperbolic tangent
activation function typically performs better than the logistic sigmoid. It resembles
the identity function more closely, in the sense that tanh(0) = 0 while Ïƒ (0) = 12 .
Because tanh is similar to the identity function near 0, training a deep neural
network yÌ‚ = wî€¾ tanh(U î€¾ tanh(V î€¾x)) resembles training a linear model yÌ‚ =
wî€¾ U î€¾ V î€¾x so long as the activations of the network can be kept small. This
makes training the tanh network easier.
Sigmoidal activation functions are more common in settings other than feedforward networks. Recurrent networks, many probabilistic models, and some
autoencoders have additional requirements that rule out the use of piecewise
linear activation functions and make sigmoidal units more appealing despite the
drawbacks of saturation.

195

CHAPTER 6. DEEP FEEDFORWARD NETWORKS

6.3.3

Other Hidden Units

Many other types of hidden units are possible, but are used less frequently.
In general, a wide variety of diï¬€erentiable functions perform perfectly well.
Many unpublished activation functions perform just as well as the popular ones.
To provide a concrete example, the authors tested a feedforward network using
h = cos(W x + b) on the MNIST dataset and obtained an error rate of less than
1%, which is competitive with results obtained using more conventional activation
functions. During research and development of new techniques, it is common
to test many diï¬€erent activation functions and ï¬?nd that several variations on
standard practice perform comparably. This means that usually new hidden unit
types are published only if they are clearly demonstrated to provide a signiï¬?cant
improvement. New hidden unit types that perform roughly comparably to known
types are so common as to be uninteresting.
It would be impractical to list all of the hidden unit types that have appeared
in the literature. We highlight a few especially useful and distinctive ones.
One possibility is to not have an activation g (z) at all. One can also think of
this as using the identity function as the activation function. We have already
seen that a linear unit can be useful as the output of a neural network. It may
also be used as a hidden unit. If every layer of the neural network consists of only
linear transformations, then the network as a whole will be linear. However, it
is acceptable for some layers of the neural network to be purely linear. Consider
a neural network layer with n inputs and p outputs, h = g(W î€¾x + b). We may
replace this with two layers, with one layer using weight matrix U and the other
using weight matrix V . If the ï¬?rst layer has no activation function, then we have
essentially factored the weight matrix of the original layer based on W . The
factored approach is to compute h = g(V î€¾U î€¾ x + b). If U produces q outputs,
then U and V together contain only (n + p)q parameters, while W contains np
parameters. For small q, this can be a considerable saving in parameters. It
comes at the cost of constraining the linear transformation to be low-rank, but
these low-rank relationships are often suï¬ƒcient. Linear hidden units thus oï¬€er an
eï¬€ective way of reducing the number of parameters in a network.
Softmax units are another kind of unit that is usually used as an output (as
described in section 6.2.2.3) but may sometimes be used as a hidden unit. Softmax
units naturally represent a probability distribution over a discrete variable with k
possible values, so they may be used as a kind of switch. These kinds of hidden
units are usually only used in more advanced architectures that explicitly learn to
manipulate memory, described in section 10.12.
196

CHAPTER 6. DEEP FEEDFORWARD NETWORKS

A few other reasonably common hidden unit types include:
î€?
î€‘
â€¢ Radial basis function or RBF unit: hi = exp âˆ’ Ïƒ12 ||W:,i âˆ’ x|| 2 . This
i
function becomes more active as x approaches a template W:,i . Because it
saturates to 0 for most x, it can be diï¬ƒcult to optimize.
â€¢ Softplus: g(a) = Î¶ (a) = log(1 + ea). This is a smooth version of the rectiï¬?er,
introduced by Dugas et al. (2001) for function approximation and by Nair
and Hinton (2010) for the conditional distributions of undirected probabilistic
models. Glorot et al. (2011a) compared the softplus and rectiï¬?er and found
better results with the latter. The use of the softplus is generally discouraged.
The softplus demonstrates that the performance of hidden unit types can
be very counterintuitiveâ€”one might expect it to have an advantage over
the rectiï¬?er due to being diï¬€erentiable everywhere or due to saturating less
completely, but empirically it does not.
â€¢ Hard tanh: this is shaped similarly to the tanh and the rectiï¬?er but unlike
the latter, it is bounded, g(a) = max(âˆ’ 1, min(1 , a)). It was introduced
by Collobert (2004).
Hidden unit design remains an active area of research and many useful hidden
unit types remain to be discovered.

6.4

Architecture Design

Another key design consideration for neural networks is determining the architecture.
The word architecture refers to the overall structure of the network: how many
units it should have and how these units should be connected to each other.
Most neural networks are organized into groups of units called layers. Most
neural network architectures arrange these layers in a chain structure, with each
layer being a function of the layer that preceded it. In this structure, the ï¬?rst layer
is given by
î€?
î€‘
h(1) = g (1) W (1)î€¾x + b (1) ,
(6.40)
the second layer is given by
h
and so on.

(2)

(2)

=g

î€?
î€‘
(2)
(2)î€¾ (1)
W
h +b
,
197

(6.41)

CHAPTER 6. DEEP FEEDFORWARD NETWORKS

In these chain-based architectures, the main architectural considerations are
to choose the depth of the network and the width of each layer. As we will see,
a network with even one hidden layer is suï¬ƒcient to ï¬?t the training set. Deeper
networks often are able to use far fewer units per layer and far fewer parameters
and often generalize to the test set, but are also often harder to optimize. The
ideal network architecture for a task must be found via experimentation guided by
monitoring the validation set error.

6.4.1

Universal Approximation Properties and Depth

A linear model, mapping from features to outputs via matrix multiplication, can
by deï¬?nition represent only linear functions. It has the advantage of being easy to
train because many loss functions result in convex optimization problems when
applied to linear models. Unfortunately, we often want to learn nonlinear functions.
At ï¬?rst glance, we might presume that learning a nonlinear function requires
designing a specialized model family for the kind of nonlinearity we want to learn.
Fortunately, feedforward networks with hidden layers provide a universal approximation framework. Speciï¬?cally, the universal approximation theorem (Hornik
et al., 1989; Cybenko, 1989) states that a feedforward network with a linear output
layer and at least one hidden layer with any â€œsquashingâ€? activation function (such
as the logistic sigmoid activation function) can approximate any Borel measurable
function from one ï¬?nite-dimensional space to another with any desired non-zero
amount of error, provided that the network is given enough hidden units. The
derivatives of the feedforward network can also approximate the derivatives of the
function arbitrarily well (Hornik et al., 1990). The concept of Borel measurability
is beyond the scope of this book; for our purposes it suï¬ƒces to say that any
continuous function on a closed and bounded subset of R n is Borel measurable
and therefore may be approximated by a neural network. A neural network may
also approximate any function mapping from any ï¬?nite dimensional discrete space
to another. While the original theorems were ï¬?rst stated in terms of units with
activation functions that saturate both for very negative and for very positive
arguments, universal approximation theorems have also been proved for a wider
class of activation functions, which includes the now commonly used rectiï¬?ed linear
unit (Leshno et al., 1993).
The universal approximation theorem means that regardless of what function
we are trying to learn, we know that a large MLP will be able to represent this
function. However, we are not guaranteed that the training algorithm will be able
to learn that function. Even if the MLP is able to represent the function, learning
can fail for two diï¬€erent reasons. First, the optimization algorithm used for training
198

CHAPTER 6. DEEP FEEDFORWARD NETWORKS

may not be able to ï¬?nd the value of the parameters that corresponds to the desired
function. Second, the training algorithm might choose the wrong function due to
overï¬?tting. Recall from section 5.2.1 that the â€œno free lunchâ€? theorem shows that
there is no universally superior machine learning algorithm. Feedforward networks
provide a universal system for representing functions, in the sense that, given a
function, there exists a feedforward network that approximates the function. There
is no universal procedure for examining a training set of speciï¬?c examples and
choosing a function that will generalize to points not in the training set.
The universal approximation theorem says that there exists a network large
enough to achieve any degree of accuracy we desire, but the theorem does not
say how large this network will be. Barron (1993) provides some bounds on the
size of a single-layer network needed to approximate a broad class of functions.
Unfortunately, in the worse case, an exponential number of hidden units (possibly
with one hidden unit corresponding to each input conï¬?guration that needs to be
distinguished) may be required. This is easiest to see in the binary case: the
n
number of possible binary functions on vectors v âˆˆ {0, 1}n is 22 and selecting
one such function requires 2n bits, which will in general require O(2 n ) degrees of
freedom.
In summary, a feedforward network with a single layer is suï¬ƒcient to represent
any function, but the layer may be infeasibly large and may fail to learn and
generalize correctly. In many circumstances, using deeper models can reduce the
number of units required to represent the desired function and can reduce the
amount of generalization error.
There exist families of functions which can be approximated eï¬ƒciently by an
architecture with depth greater than some value d, but which require a much larger
model if depth is restricted to be less than or equal to d. In many cases, the number
of hidden units required by the shallow model is exponential in n. Such results
were ï¬?rst proved for models that do not resemble the continuous, diï¬€erentiable
neural networks used for machine learning, but have since been extended to these
models. The ï¬?rst results were for circuits of logic gates (HÃ¥stad, 1986). Later
work extended these results to linear threshold units with non-negative weights
(HÃ¥stad and Goldmann, 1991; Hajnal et al., 1993), and then to networks with
continuous-valued activations (Maass, 1992; Maass et al., 1994). Many modern
neural networks use rectiï¬?ed linear units. Leshno et al. (1993) demonstrated
that shallow networks with a broad family of non-polynomial activation functions,
including rectiï¬?ed linear units, have universal approximation properties, but these
results do not address the questions of depth or eï¬ƒciencyâ€”they specify only that
a suï¬ƒciently wide rectiï¬?er network could represent any function. Montufar et al.
199

CHAPTER 6. DEEP FEEDFORWARD NETWORKS

(2014) showed that functions representable with a deep rectiï¬?er net can require
an exponential number of hidden units with a shallow (one hidden layer) network.
More precisely, they showed that piecewise linear networks (which can be obtained
from rectiï¬?er nonlinearities or maxout units) can represent functions with a number
of regions that is exponential in the depth of the network. Figure 6.5 illustrates how
a network with absolute value rectiï¬?cation creates mirror images of the function
computed on top of some hidden unit, with respect to the input of that hidden
unit. Each hidden unit speciï¬?es where to fold the input space in order to create
mirror responses (on both sides of the absolute value nonlinearity). By composing
these folding operations, we obtain an exponentially large number of piecewise
linear regions which can capture all kinds of regular (e.g., repeating) patterns.

Figure 6.5: An intuitive, geometric explanation of the exponential advantage of deeper
rectiï¬?er networks formally by Montufar et al. (2014). (Left)An absolute value rectiï¬?cation
unit has the same output for every pair of mirror points in its input. The mirror axis
of symmetry is given by the hyperplane deï¬?ned by the weights and bias of the unit. A
function computed on top of that unit (the green decision surface) will be a mirror image
of a simpler pattern across that axis of symmetry. (Center)The function can be obtained
by folding the space around the axis of symmetry. (Right)Another repeating pattern can
be folded on top of the ï¬?rst (by