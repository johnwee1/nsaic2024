 . , Ï†k specifying the probability of each of the
outcomes. Note that these numbers must satisfy (cid:80)k
i=1 Ï†i = 1. We will de-
sign a parameterized model that outputs Ï†1, . . . , Ï†k satisfying this constraint
given the input x.

We introduce k groups of parameters Î¸1, . . . , Î¸k, each of them being a
k x to represent

Intuitively, we would like to use Î¸(cid:62)

1 x, . . . , Î¸(cid:62)

vector in Rd.

25

Ï†1, . . . , Ï†k, the probabilities P (y = 1 | x; Î¸), . . . , P (y = k | x; Î¸). However,
there are two issues with such a direct approach. First, Î¸(cid:62)
j x is not neces-
sarily within [0, 1]. Second, the summation of Î¸(cid:62)
j xâ€™s is not necessarily 1.
1 x, Â· Â· Â· , Î¸(cid:62)
Thus, instead, we will use the softmax function to turn (Î¸(cid:62)
k x) into
a probability vector with nonnegative entries that sum up to 1.

Deï¬ne the softmax function softmax : Rk â†’ Rk as
ï£¹

ï£®

softmax(t1, . . . , tk) =

ï£¯
ï£¯
ï£°

.

ï£º
ï£º
ï£»

(2.9)

(cid:80)k

exp(t1)
j=1 exp(tj )
...

exp(tk)
j=1 exp(tj )

(cid:80)k

The inputs to the softmax function, the vector t here, are often called log-
its. Note that by deï¬nition, the output of the softmax function is always a
probability vector whose entries are nonnegative and sum up to 1.

Let (t1, . . . , tk) = (Î¸(cid:62)

k x). We apply the softmax function to
(t1, . . . , tk), and use the output as the probabilities P (y = 1 | x; Î¸), . . . , P (y =
k | x; Î¸). We obtain the following probabilistic model:

1 x, Â· Â· Â· , Î¸(cid:62)

ï£¹

ï£®

ï£¯
ï£°

P (y = 1 | x; Î¸)
...
P (y = k | x; Î¸)

ï£º
ï£» = softmax(t1, Â· Â· Â· , tk) =

ï£®

ï£¯
ï£¯
ï£¯
ï£°

j x)

exp(Î¸(cid:62)
1 x)
j=1 exp(Î¸(cid:62)
...

exp(Î¸(cid:62)
k x)
j=1 exp(Î¸(cid:62)

j x)

(cid:80)k

(cid:80)k

ï£¹

ï£º
ï£º
ï£º
ï£»

.

(2.10)

For notational convenience, we will let Ï†i = exp(ti)
equation above can be written as:

(cid:80)k

j=1 exp(tj )

. More succinctly, the

P (y = i | x; Î¸) = Ï†i =

exp(ti)
j=1 exp(tj)

(cid:80)k

=

exp(Î¸(cid:62)
i x)
j=1 exp(Î¸(cid:62)

j x)

(cid:80)k

.

(2.11)

Next, we compute the negative log-likelihood of a single example (x, y).

âˆ’ log p(y | x, Î¸) = âˆ’ log

(cid:32)

exp(ty)
j=1 exp(tj)

(cid:80)k

(cid:33)

(cid:32)

= âˆ’ log

exp(Î¸(cid:62)
y x)
j=1 exp(Î¸(cid:62)

j x)

(cid:80)k

(cid:33)

(2.12)

Thus, the loss function, the negative log-likelihood of the training data, is
given as

(cid:96)(Î¸) =

n
(cid:88)

i=1

âˆ’ log

(cid:32) exp(Î¸(cid:62)

y(i)x(i))

(cid:80)k

j=1 exp(Î¸(cid:62)

j x(i))

(cid:33)

.

(2.13)

Itâ€™s convenient to deï¬ne the cross-entropy loss (cid:96)ce : Rk Ã— {1, . . . , k} â†’ Râ‰¥0,
which modularizes in the complex equation above:1

26

(cid:96)ce((t1, . . . , tk), y) = âˆ’ log

(cid:32)

exp(ty)
j=1 exp(tj)

(cid:80)k

(cid:33)

.

With this notation, we can simply rewrite equation (2.13) as

(cid:96)(Î¸) =

n
(cid:88)

i=1

(cid:96)ce((Î¸(cid:62)

1 x(i), . . . , Î¸(cid:62)

k x(i)), y(i)) .

(2.14)

(2.15)

Moreover, conveniently, the cross-entropy loss also has a simple gradient. Let
t = (t1, . . . , tk), and recall Ï†i = exp(ti)
. By basic calculus, we can derive

(cid:80)k

j=1 exp(tj )

âˆ‚(cid:96)ce(t, y)
âˆ‚ti

= Ï†i âˆ’ 1{y = i} ,

(2.16)

where 1{Â·} is the indicator function, that is, 1{y = i} = 1 if y = i, and
1{y = i} = 0 if y (cid:54)= i. Alternatively, in vectorized notations, we have the
following form which will be useful for Chapter 7:

âˆ‚(cid:96)ce(t, y)
âˆ‚t

= Ï† âˆ’ ey ,

(2.17)

where es âˆˆ Rk is the s-th natural basis vector (where the s-th entry is 1 and
all other entries are zeros.) Using Chain rule, we have that

âˆ‚(cid:96)ce((Î¸(cid:62)

1 x, . . . , Î¸(cid:62)
âˆ‚Î¸i

k x), y)

=

âˆ‚(cid:96)(t, y)
âˆ‚ti

Â·

âˆ‚ti
âˆ‚Î¸i

= (Ï†i âˆ’ 1{y = i}) Â· x .

(2.18)

Therefore, the gradient of the loss with respect to the part of parameter Î¸i is

âˆ‚(cid:96)(Î¸)
âˆ‚Î¸i

=

n
(cid:88)

(Ï†(j)

i âˆ’ 1{y(j) = i}) Â· x(j) ,

j=1

(2.19)

i x(j))

i = exp(Î¸(cid:62)

where Ï†(j)
is the probability that the model predicts item i
for example x(j). With the gradients above, one can implement (stochastic)
gradient descent to minimize the loss function (cid:96)(Î¸).

s=1 exp(Î¸(cid:62)

s x(j))

(cid:80)k

1There are some ambiguity in the naming here. Some people call the cross-entropy loss
the function that maps the probability vector (the Ï† in our language) and label y to the
ï¬nal real number, and call our version of cross-entropy loss softmax-cross-entropy loss.
We choose our current naming convention because itâ€™s consistent with the naming of most
modern deep learning library such as PyTorch and Jax.

27

2.4 Another algorithm for maximizing (cid:96)(Î¸)

Returning to logistic regression with g(z) being the sigmoid function, letâ€™s
now talk about a diï¬€erent algorithm for maximizing (cid:96)(Î¸).

To get us started, letâ€™s consider Newtonâ€™s method for ï¬nding a zero of a
function. Speciï¬cally, suppose we have some function f : R (cid:55)â†’ R, and we
wish to ï¬nd a value of Î¸ so that f (Î¸) = 0. Here, Î¸ âˆˆ R is a real number.
Newtonâ€™s method performs the following update:

Î¸ := Î¸ âˆ’

f (Î¸)
f (cid:48)(Î¸)

.

This method has a natural interpretation in which we can think of it as
approximating the function f via a linear function that is tangent to f at
the current guess Î¸, solving for where that linear function equals to zero, and
letting the next guess for Î¸ be where that linear function is zero.

Hereâ€™s a picture of the Newtonâ€™s method in action:
In the leftmost ï¬gure, we see the function f plotted along with the line
y = 0. Weâ€™re trying to ï¬nd Î¸ so that f (Î¸) = 0; the value of Î¸ that achieves this
is about 1.3. Suppose we initialized the algorithm with Î¸ = 4.5. Newtonâ€™s
method then ï¬ts a straight line tangent to f at Î¸ = 4.5, and solves for the
where that line evaluates to 0. (Middle ï¬gure.) This give us the next guess
for Î¸, which is about 2.8. The rightmost ï¬gure shows the result of running
one more iteration, which the updates Î¸ to about 1.8. After a few more
iterations, we rapidly approach Î¸ = 1.3.

Newtonâ€™s method gives a way of getting to f (Î¸) = 0. What if we want to
use it to maximize some function (cid:96)? The maxima of (cid:96) correspond to points
where its ï¬rst derivative (cid:96)(cid:48)(Î¸) is zero. So, by letting f (Î¸) = (cid:96)(cid:48)(Î¸), we can use
the same algorithm to maximize (cid:96), and we obtain update rule:

Î¸ := Î¸ âˆ’

(cid:96)(cid:48)(Î¸)
(cid:96)(cid:48)(cid:48)(Î¸)

.

(Something to think about: How would this change if we wanted to use
Newtonâ€™s method to minimize rather than maximize a function?)

11.522.533.544.55âˆ’100102030405060xf(x)11.522.533.544.55âˆ’100102030405060xf(x)11.522.533.544.55âˆ’100102030405060xf(x)28

Lastly, in our logistic regression setting, Î¸ is vector-valued, so we need to
generalize Newtonâ€™s method to this setting. The generalization of Newtonâ€™s
method to this multidimensional setting (also called the Newton-Raphson
method) is given by

Î¸ := Î¸ âˆ’ H âˆ’1âˆ‡Î¸(cid:96)(Î¸).

Here, âˆ‡Î¸(cid:96)(Î¸) is, as usual, the vector of partial derivatives of (cid:96)(Î¸) with respect
to the Î¸iâ€™s; and H is an d-by-d matrix (actually, d+1âˆ’byâˆ’d+1, assuming that
we include the intercept term) called the Hessian, whose entries are given
by

Hij =

âˆ‚2(cid:96)(Î¸)
âˆ‚Î¸iâˆ‚Î¸j

.

Newtonâ€™s method typically enjoys faster convergence than (batch) gra-
dient descent, and requires many fewer iterations to get very close to the
minimum. One iteration of Newtonâ€™s can, however, be more expensive than
one iteration of gradient descent, since it requires ï¬nding and inverting an
d-by-d Hessian; but so long as d is not too large, it is usually much faster
overall. When Newtonâ€™s method is applied to maximize the logistic regres-
sion log likelihood function (cid:96)(Î¸), the resulting method is also called Fisher
scoring.

Chapter 3

Generalized linear models

So far, weâ€™ve seen a regression example, and a classiï¬cation example. In the
regression example, we had y|x; Î¸ âˆ¼ N (Âµ, Ïƒ2), and in the classiï¬cation one,
y|x; Î¸ âˆ¼ Bernoulli(Ï†), for some appropriate deï¬nitions of Âµ and Ï† as functions
of x and Î¸.
In this section, we will show that both of these methods are
special cases of a broader family of models, called Generalized Linear Models
(GLMs).1 We will also show how other models in the GLM family can be
derived and applied to other classiï¬cation and regression problems.

3.1 The exponential family

To work our way up to GLMs, we will begin by deï¬ning exponential family
distributions. We say that a class of distributions is in the exponential family
if it can be written in the form

p(y; Î·) = b(y) exp(Î·T T (y) âˆ’ a(Î·))

(3.1)

Here, Î· is called the natural parameter (also called the canonical param-
eter) of the distribution; T (y) is the suï¬ƒcient statistic (for the distribu-
tions we consider, it will often be the case that T (y) = y); and a(Î·) is the log
partition function. The quantity eâˆ’a(Î·) essentially plays the role of a nor-
malization constant, that makes sure the distribution p(y; Î·) sums/integrates
over y to 1.

A ï¬xed choice of T , a and b deï¬nes a family (or set) of distributions that
is parameterized by Î·; as we vary Î·, we then get diï¬€erent distributions within
this family.

1The presentation of the material in this section takes inspiration from Michael I.
Jordan, Learning in graphical models (unpublished book draft), and also McCullagh and
Nelder, Generalized Linear Models (2nd ed.).

29

30

We now show that the Bernoulli and the Gaussian distributions are ex-
amples of exponential family distributions. The Bernoulli distribution with
mean Ï†, written Bernoulli(Ï†), speciï¬es a distribution over y âˆˆ {0, 1}, so that
p(y = 1; Ï†) = Ï†; p(y = 0; Ï†) = 1 âˆ’ Ï†. As we vary Ï†, we obtain Bernoulli
distributions with diï¬€erent means. We now show that this class of Bernoulli
distributions, ones obtained by varying Ï†, is in the exponential family; i.e.,
that there is a choice of T , a and b so that Equation (3.1) becomes exactly
the class of Bernoulli distributions.

We write the Bernoulli distribution as:

p(y; Ï†) = Ï†y(1 âˆ’ Ï†)1âˆ’y

= exp(y log Ï† + (1 âˆ’ y) log(1 âˆ’ Ï†))
(cid:18) Ï†

(cid:19)(cid:19)

(cid:18)(cid:18)

= exp

log

y + log(1 âˆ’ Ï†)

.

(cid:19)

1 âˆ’ Ï†

Thus, the natural parameter is given by Î· = log(Ï†/(1 âˆ’ Ï†)). Interestingly, if
we invert this deï¬nition for Î· by solving for Ï† in terms of Î·, we obtain Ï† =
1/(1 + eâˆ’Î·). This is the familiar sigmoid function! This will come up again
when we derive logistic regression as a GLM. To complete the formulation
of the Bernoulli distribution as an exponential family distribution, we also
have

T (y) = y
a(Î·) = âˆ’ log(1 âˆ’ Ï†)

= log(1 + eÎ·)

b(y) = 1

This shows that the Bernoulli distribution can be written in the form of
Equation (3.1), using an appropriate choice of T , a and b.

Letâ€™s now move on to consider the Gaussian distribution. Recall that,
when deriving linear regression, the value of Ïƒ2 had no eï¬€ect on our ï¬nal
choice of Î¸ and hÎ¸(x). Thus, we can choose an arbitrary value for Ïƒ2 without
changing anything. To simplify the derivation below, letâ€™s set Ïƒ2 = 1.2 We

2If we leave Ïƒ2 as a variable, the Gaussian distribution can also be shown to be in the
exponential family, where Î· âˆˆ R2 is now a 2-dimension vector that depends on both Âµ and
Ïƒ. For the purposes of GLMs, however, the Ïƒ2 parameter can also be treated by considering
a more general deï¬nition of the exponential family: p(y; Î·, Ï„ ) = b(a, Ï„ ) exp((Î·T T (y) âˆ’
a(Î·))/c(Ï„ )). Here, Ï„ is called the dispersion parameter, and for the Gaussian, c(Ï„ ) = Ïƒ2;
but given our simpliï¬cation above, we wonâ€™t need the more general deï¬nition for the
examples we will consider here.

then have:

p(y; Âµ) =

=

1
âˆš
2Ï€
1
âˆš
2Ï€

(cid:18)

exp

âˆ’

(cid:18)

exp

âˆ’

1
2
1
2

(cid:19)

(cid:18)

(y âˆ’ Âµ)2

(cid:19)

y2

Â· exp

Âµy âˆ’

31

(cid:19)

1
2

Âµ2

Thus, we see that the Gaussian is in the exponential family, with

Î· = Âµ
T (y) = y
a(Î·) = Âµ2/2
= Î·2/2
âˆš
b(y) = (1/

2Ï€) exp(âˆ’y2/2).

Thereâ€™re many other distributions that are members of the exponen-
tial family: The multinomial (which weâ€™ll see later), the Poisson (for mod-
elling count-data; also see the problem set); the gamma and the exponen-
tial (for modelling continuous, non-negative random variables, such as time-
intervals); the beta and the Dirichlet (for distributions over probabilities);
and many more.
In the next section, we will describe a general â€œrecipeâ€
for constructing models in which y (given x and Î¸) comes from any of these
distributions.

3.2 Constructing GLMs

Suppose you would like to build a model to estimate the number y of cus-
tomers arriving in your store (or number of page-views on your website) in
any given hour, based on certain features x such as store promotions, recent
advertising, weather, day-of-week, etc. We know that the Poisson distribu-
tion usually gives a good model for numbers of visitors. Knowing this, how
can we come up with a model for our problem? Fortunately, the Poisson is an
exponential family distribution, so we can apply a Generalized Linear Model
(GLM). In this section, we will we will describe a method for constructing
GLM models for problems such as these.

More generally, consider a classiï¬cation or regression problem where we
would like to predict the value of some random variable y as a function of
x. To derive a GLM for this problem, we will make the following three
assumptions about the conditional distribution of y given x and about our
model:

32

1. y | x; Î¸ âˆ¼ ExponentialFamily(Î·). I.e., given x and Î¸, the distribution of

y follows some exponential family distribution, with parameter Î·.

2. Given x, our goal is to predict the expected value of T (y) given x.
In most of our examples, we will have T (y) = y, so this means we
would like the prediction h(x) output by our learned hypothesis h to
satisfy h(x) = E[y|x].
(Note that this assumption is satisï¬ed in the
choices for hÎ¸(x) for both logistic regression and linear regression. For
instance, in logistic regression, we had hÎ¸(x) = p(y = 1|x; Î¸) = 0 Â· p(y =
0|x; Î¸) + 1 Â· p(y = 1|x; Î¸) = E[y|x; Î¸].)

3. The natural parameter Î· and the inputs x are related linearly: Î· = Î¸T x.

(Or, if Î· is vector-valued, then Î·i = Î¸T

i x.)

The third of these assumptions might seem the least well justiï¬ed of
the above, and it might be better thought of as a â€œdesign choiceâ€ in our
recipe for designing GLMs, rather than as an assumption per se. These
three assumptions/design choices will allow us to derive a very elegant class
of learning algorithms, namely GLMs, that have many desirable properties
such as ease of learning. Furthermore, the resulting models are often very
eï¬€ective for modelling diï¬€erent types of distributions over y; for example, we
will shortly show that both logistic regression and ordinary least squares can
both be derived as GLMs.

3.2.1 Ordinary least squares

To show that ordinary least squares is a special case of the GLM family
of models, consider the setting where the target variable y (also called the
response variable in GLM terminology) is continuous, and we model the
conditional distribution of y given x as a Gaussian N (Âµ, Ïƒ2). (Here, Âµ may
depend x.) So, we let the ExponentialF amily(Î·) distribution above be
the Gaussian distribution. As we saw pr