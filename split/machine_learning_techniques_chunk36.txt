tting, especially when you
do not have a lot of training data. We will come back to this later.

You can easily get a model’s list of layers, to fetch a layer by its index, or you can fetch
it by name:

>>> model.layers
[<tensorflow.python.keras.layers.core.Flatten at 0x132414e48>,
 <tensorflow.python.keras.layers.core.Dense at 0x1324149b0>,
 <tensorflow.python.keras.layers.core.Dense at 0x1356ba8d0>,
 <tensorflow.python.keras.layers.core.Dense at 0x13240d240>]
>>> hidden1 = model.layers[1]
>>> hidden1.name
'dense'
>>> model.get_layer('dense') is hidden1
True

All  the  parameters  of  a  layer  can  be  accessed  using  its  get_weights()  and
set_weights() methods. For a Dense layer, this includes both the connection weights
and the bias terms:

>>> weights, biases = hidden1.get_weights()
>>> weights
array([[ 0.02448617, -0.00877795, -0.02189048, ..., -0.02766046,
         0.03859074, -0.06889391],
       ...,
       [-0.06022581,  0.01577859, -0.02585464, ..., -0.00527829,
         0.00272203, -0.06793761]], dtype=float32)
>>> weights.shape
(784, 300)
>>> biases
array([0., 0., 0., 0., 0., 0., 0., 0., 0., ...,  0., 0., 0.], dtype=float32)
>>> biases.shape
(300,)

Notice  that  the  Dense  layer  initialized  the  connection  weights  randomly  (which  is
needed to break symmetry, as we discussed earlier), and the biases were initialized to
zeros, which is fine. If you ever want to use a different initialization method, you can
set  kernel_initializer  (kernel  is  another  name  for  the  matrix  of  connection

Implementing MLPs with Keras 

| 

301

weights)  or  bias_initializer  when  creating  the  layer.  We  will  discuss  initializers
further in Chapter 11, but if you want the full list, see https://keras.io/initializers/.

The shape of the weight matrix depends on the number of inputs.
This  is  why  it  is  recommended  to  specify  the  input_shape  when
creating the first layer in a Sequential model. However, if you do
not specify the input shape, it’s OK: Keras will simply wait until it
knows the input shape before it actually builds the model. This will
happen either when you feed it actual data (e.g., during training),
or  when  you  call  its  build()  method.  Until  the  model  is  really
built, the layers will not have any weights, and you will not be able
to do certain things (such as print the model summary or save the
model). So, if you know the input shape when creating the model,
it is best to specify it.

Compiling the model

After a model is created, you must call its compile() method to specify the loss func‐
tion  and  the  optimizer  to  use.  Optionally,  you  can  specify  a  list  of  extra  metrics  to
compute during training and evaluation:

model.compile(loss="sparse_categorical_crossentropy",
              optimizer="sgd",
              metrics=["accuracy"])

Using loss="sparse_categorical_crossentropy" is equivalent to
loss=keras.losses.sparse_categorical_crossentropy.
using 
Similarly,  specifying  optimizer="sgd"  is  equivalent  to  specifying
optimizer=keras.optimizers.SGD(), and metrics=["accuracy"]
is  equivalent 
cal_accuracy] (when using this loss). We will use many other los‐
ses,  optimizers,  and  metrics  in  this  book;  for  the  full  lists,  see
https://keras.io/losses, 
https://
keras.io/metrics.

to  metrics=[keras.metrics.sparse_categori

https://keras.io/optimizers, 

and 

This code requires some explanation. First, we use the "sparse_categorical_cross
entropy" loss because we have sparse labels (i.e., for each instance, there is just a tar‐
get class index, from 0 to 9 in this case), and the classes are exclusive. If instead we
had  one  target  probability  per  class  for  each  instance  (such  as  one-hot  vectors,  e.g.
[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.] to represent class 3), then we would
need to use the "categorical_crossentropy" loss instead. If we were doing binary
classification (with one or more binary labels), then we would use the "sigmoid" (i.e.,
logistic)  activation  function  in  the  output  layer  instead  of  the  "softmax"  activation
function, and we would use the "binary_crossentropy" loss.

302 

| 

Chapter 10: Introduction to Artificial Neural Networks with Keras

If you want to convert sparse labels (i.e., class indices) to one-hot
vector labels, use the keras.utils.to_categorical() function. To
go  the  other  way  round,  use  the  np.argmax()  function  with
axis=1.

Regarding the optimizer, "sgd" means that we will train the model using simple Sto‐
chastic  Gradient  Descent.  In  other  words,  Keras  will  perform  the  backpropagation
algorithm  described  earlier  (i.e.,  reverse-mode  autodiff  plus  Gradient  Descent).  We
will  discuss  more  efficient  optimizers  in  Chapter  11  (they  improve  the  Gradient
Descent part, not the autodiff).

When using the SGD optimizer, it is important to tune the learning
rate. So, you will generally want to use optimizer=keras.optimiz
ers.SGD(lr=???)  to  set  the  learning  rate,  rather  than  opti
mizer="sgd", which defaults to lr=0.01.

Finally, since this is a classifier, it’s useful to measure its "accuracy" during training
and evaluation.

Training and evaluating the model

Now  the  model  is  ready  to  be  trained.  For  this  we  simply  need  to  call  its  fit()
method:

>>> history = model.fit(X_train, y_train, epochs=30,
...                     validation_data=(X_valid, y_valid))
...
Train on 55000 samples, validate on 5000 samples
Epoch 1/30
55000/55000 [======] - 3s 49us/sample - loss: 0.7218     - accuracy: 0.7660
                                      - val_loss: 0.4973 - val_accuracy: 0.8366
Epoch 2/30
55000/55000 [======] - 2s 45us/sample - loss: 0.4840     - accuracy: 0.8327
                                      - val_loss: 0.4456 - val_accuracy: 0.8480
[...]
Epoch 30/30
55000/55000 [======] - 3s 53us/sample - loss: 0.2252     - accuracy: 0.9192
                                      - val_loss: 0.2999 - val_accuracy: 0.8926

We pass it the input features (X_train) and the target classes (y_train), as well as the
number of epochs to train (or else it would default to just 1, which would definitely
not be enough to converge to a good solution). We also pass a validation set (this is
optional). Keras will measure the loss and the extra metrics on this set at the end of
each epoch, which is very useful to see how well the model really performs. If the per‐
formance on the training set is much better than on the validation set, your model is

Implementing MLPs with Keras 

| 

303

probably  overfitting  the  training  set  (or  there  is  a  bug,  such  as  a  data  mismatch
between the training set and the validation set).

And  that’s  it!  The  neural  network  is  trained.15  At  each  epoch  during  training,  Keras
displays  the  number  of  instances  processed  so  far  (along  with  a  progress  bar),  the
mean training time per sample, and the loss and accuracy (or any other extra metrics
you  asked  for)  on  both  the  training  set  and  the  validation  set.  You  can  see  that  the
training  loss  went  down,  which  is  a  good  sign,  and  the  validation  accuracy  reached
89.26% after 30 epochs. That’s not too far from the training accuracy, so there does
not seem to be much overfitting going on.

Instead  of  passing  a  validation  set  using  the  validation_data
argument,  you  could  set  validation_split  to  the  ratio  of  the
training set that you want Keras to use for validation. For example,
validation_split=0.1  tells  Keras  to  use  the  last  10%  of  the  data
(before shuffling) for validation.

If the training set was very skewed, with some classes being overrepresented and oth‐
ers  underrepresented,  it  would  be  useful  to  set  the  class_weight  argument  when
calling  the  fit()  method,  which  would  give  a  larger  weight  to  underrepresented
classes and a lower weight to overrepresented classes. These weights would be used by
Keras  when  computing  the  loss.  If  you  need  per-instance  weights,  set  the  sam
ple_weight argument (if both class_weight and sample_weight are provided, Keras
multiplies them). Per-instance weights could be useful if some instances were labeled
by experts while others were labeled using a crowdsourcing platform: you might want
to give more weight to the former. You can also provide sample weights (but not class
weights) for the validation set by adding them as a third item in the validation_data
tuple.

The  fit()  method  returns  a  History  object  containing  the  training  parameters
(history.params),  the  list  of  epochs  it  went  through  (history.epoch),  and  most
importantly a dictionary (history.history) containing the loss and extra metrics it
measured  at  the  end  of  each  epoch  on  the  training  set  and  on  the  validation  set  (if
any).  If  you  use  this  dictionary  to  create  a  pandas  DataFrame  and  call  its  plot()
method, you get the learning curves shown in Figure 10-12:

15 If your training or validation data does not match the expected shape, you will get an exception. This is per‐

haps the most common error, so you should get familiar with the error message. The message is actually quite
clear: for example, if you try to train this model with an array containing flattened images
(X_train.reshape(-1, 784)), then you will get the following exception: “ValueError: Error when checking
input: expected flatten_input to have 3 dimensions, but got array with shape (60000, 784).”

304 

| 

Chapter 10: Introduction to Artificial Neural Networks with Keras

import pandas as pd
import matplotlib.pyplot as plt

pd.DataFrame(history.history).plot(figsize=(8, 5))
plt.grid(True)
plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]
plt.show()

Figure 10-12. Learning curves: the mean training loss and accuracy measured over each
epoch, and the mean validation loss and accuracy measured at the end of each epoch

You  can  see  that  both  the  training  accuracy  and  the  validation  accuracy  steadily
increase  during  training,  while  the  training  loss  and  the  validation  loss  decrease.
Good! Moreover, the validation curves are close to the training curves, which means
that there is not too much overfitting. In this particular case, the model looks like it
performed  better  on  the  validation  set  than  on  the  training  set  at  the  beginning  of
training. But that’s not the case: indeed, the validation error is computed at the end of
each epoch, while the training error is computed using a running mean during each
epoch. So the training curve should be shifted by half an epoch to the left. If you do
that,  you  will  see  that  the  training  and  validation  curves  overlap  almost  perfectly  at
the beginning of training.

When  plotting  the  training  curve,  it  should  be  shifted  by  half  an
epoch to the left.

Implementing MLPs with Keras 

| 

305

The training set performance ends up beating the validation performance, as is gen‐
erally the case when you train for long enough. You can tell that the model has not
quite converged yet, as the validation loss is still going down, so you should probably
continue  training.  It’s  as  simple  as  calling  the  fit()  method  again,  since  Keras  just
continues training where it left off (you should be able to reach close to 89% valida‐
tion accuracy).

If you are not satisfied with the performance of your model, you should go back and
tune the hyperparameters. The first one to check is the learning rate. If that doesn’t
help,  try  another  optimizer  (and  always  retune  the  learning  rate  after  changing  any
hyperparameter). If the performance is still not great, then try tuning model hyper‐
parameters  such  as  the  number  of  layers,  the  number  of  neurons  per  layer,  and  the
types  of  activation  functions  to  use  for  each  hidden  layer.  You  can  also  try  tuning
other hyperparameters, such as the batch size (it can be set in the fit() method using
the batch_size argument, which defaults to 32). We will get back to hyperparameter
tuning at the end of this chapter. Once you are satisfied with your model’s validation
accuracy,  you  should  evaluate  it  on  the  test  set  to  estimate  the  generalization  error
before  you  deploy  the  model  to  production.  You  can  easily  do  this  using  the  evalu
ate()  method  (it  also  supports  several  other  arguments,  such  as  batch_size  and
sample_weight; please check the documentation for more details):

>>> model.evaluate(X_test, y_test)
10000/10000 [==========] - 0s 29us/sample - loss: 0.3340 - accuracy: 0.8851
[0.3339798209667206, 0.8851]

As we saw in Chapter 2, it is common to get slightly lower performance on the test set
than on the validation set, because the hyperparameters are tuned on the validation
set, not the test set (however, in this example, we did not do any hyperparameter tun‐
ing,  so  the  lower  accuracy  is  just  bad  luck).  Remember  to  resist  the  temptation  to
tweak the hyperparameters on the test set, or else your estimate of the generalization
error will be too optimistic.

Using the model to make predictions

Next, we can use the model’s predict() method to make predictions on new instan‐
ces. Since we don’t have actual new instances, we will just use the first three instances
of the test set:

>>> X_new = X_test[:3]
>>> y_proba = model.predict(X_new)
>>> y_proba.round(2)
array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.01, 0.  , 0.96],
       [0.  , 0.  , 0.98, 0.  , 0.02, 0.  , 0.  , 0.  , 0.  , 0.  ],
       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],
      dtype=float32)

306 

| 

Chapter 10: Introduction to Artificial Neural Networks with Keras

As you can see, for each instance the model estimates one probability per class, from
class 0 to class 9. For example, for the first image it estimates that the probability of
class 9 (ankle boot) is 96%, the probability of class 5 (sandal) is 3%, the probability of
class  7  (sneaker)  is  1%,  and  the  probabilities  of  the  other  classes  are  negligible.  In
other words, it “believes” the first image is footwear, most likely ankle boots but pos‐
sibly sandals or sneakers. If you only care about the class with the highest estimated
probability  (even  if  that  probability  is  quite  low),  then  you  can  use  the  pre
dict_classes() method instead:

>>> y_pred = model.predict_classes(X_new)
>>> y_pred
array([9, 2, 1])
>>> np.array(class_names)[y_pred]
array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')

Here,  the  classifier  actually  classified  all  three  images  correctly  (these  images  are
shown in Figure 10-13):

>>> y_new = y_test[:3]
>>> y_new
array([9, 2, 1])

Figure 10-13. Correctly classified Fashion MNIST images

Now you know how to use the Sequential API to build, train, evaluate, and use a clas‐
sification MLP. But what about regression?

Building a Regression MLP Using the Sequential API
Let’s switch to the California housing problem and tackle it using a regression neural
network.  For  simplicity,  we  will  use  Scikit-Learn’s  fetch_california_housing()
function to load the data. This dataset is simpler than the one we used in Chapter 2,
since it contains only numerical features (there is no ocean_proximity feature), and
there is no missing value. After loading the data, we split it into a training set, a vali‐
dation set, and a test set, 