ld be able to verify that

Î¸P(w) = max

Î±,Î² : Î±iâ‰¥0

f (w) +

= âˆž.

k
(cid:88)

i=1

Î±igi(w) +

l
(cid:88)

i=1

Î²ihi(w)

(6.1)

(6.2)

Conversely, if the constraints are indeed satisï¬ed for a particular value of w,
then Î¸P(w) = f (w). Hence,

Î¸P(w) =

(cid:26) f (w)

if w satisï¬es primal constraints

âˆž otherwise.

2Readers interested in learning more about this topic are encouraged to read, e.g., R.

T. Rockarfeller (1970), Convex Analysis, Princeton University Press.

67

Thus, Î¸P takes the same value as the objective in our problem for all val-
ues of w that satisï¬es the primal constraints, and is positive inï¬nity if the
constraints are violated. Hence, if we consider the minimization problem

min
w

Î¸P(w) = min

w

max
Î±,Î² : Î±iâ‰¥0

L(w, Î±, Î²),

we see that it is the same problem (i.e., and has the same solutions as) our
original, primal problem. For later use, we also deï¬ne the optimal value of
the objective to be pâˆ— = minw Î¸P(w); we call this the value of the primal
problem.

Now, letâ€™s look at a slightly diï¬€erent problem. We deï¬ne

Î¸D(Î±, Î²) = min

L(w, Î±, Î²).

w
Here, the â€œDâ€ subscript stands for â€œdual.â€ Note also that whereas in the
deï¬nition of Î¸P we were optimizing (maximizing) with respect to Î±, Î², here
we are minimizing with respect to w.

We can now pose the dual optimization problem:

max
Î±,Î² : Î±iâ‰¥0

Î¸D(Î±, Î²) = max

Î±,Î² : Î±iâ‰¥0

min
w

L(w, Î±, Î²).

This is exactly the same as our primal problem shown above, except that the
order of the â€œmaxâ€ and the â€œminâ€ are now exchanged. We also deï¬ne the
optimal value of the dual problemâ€™s objective to be dâˆ— = maxÎ±,Î² : Î±iâ‰¥0 Î¸D(w).
How are the primal and the dual problems related? It can easily be shown

that

dâˆ— = max

Î±,Î² : Î±iâ‰¥0

min
w

L(w, Î±, Î²) â‰¤ min

w

max
Î±,Î² : Î±iâ‰¥0

L(w, Î±, Î²) = pâˆ—.

(You should convince yourself of this; this follows from the â€œmax minâ€ of a
function always being less than or equal to the â€œmin max.â€) However, under
certain conditions, we will have

dâˆ— = pâˆ—,

so that we can solve the dual problem in lieu of the primal problem. Letâ€™s
see what these conditions are.

Suppose f and the giâ€™s are convex,3 and the hiâ€™s are aï¬ƒne.4 Suppose
further that the constraints gi are (strictly) feasible; this means that there
exists some w so that gi(w) < 0 for all i.

3When f has a Hessian, then it is convex if and only if the Hessian is positive semi-
deï¬nite. For instance, f (w) = wT w is convex; similarly, all linear (and aï¬ƒne) functions
are also convex. (A function f can also be convex without being diï¬€erentiable, but we
wonâ€™t need those more general deï¬nitions of convexity here.)

4I.e., there exists ai, bi, so that hi(w) = aT

i w + bi. â€œAï¬ƒneâ€ means the same thing as

linear, except that we also allow the extra intercept term bi.

Under our above assumptions, there must exist wâˆ—, Î±âˆ—, Î²âˆ— so that wâˆ— is the
solution to the primal problem, Î±âˆ—, Î²âˆ— are the solution to the dual problem,
and moreover pâˆ— = dâˆ— = L(wâˆ—, Î±âˆ—, Î²âˆ—). Moreover, wâˆ—, Î±âˆ— and Î²âˆ— satisfy the
Karush-Kuhn-Tucker (KKT) conditions, which are as follows:

68

âˆ‚
âˆ‚wi
âˆ‚
âˆ‚Î²i

L(wâˆ—, Î±âˆ—, Î²âˆ—) = 0,

i = 1, . . . , d

L(wâˆ—, Î±âˆ—, Î²âˆ—) = 0,

i = 1, . . . , l

i gi(wâˆ—) = 0,
Î±âˆ—
gi(wâˆ—) â‰¤ 0,
Î±âˆ— â‰¥ 0,

i = 1, . . . , k
i = 1, . . . , k
i = 1, . . . , k

(6.3)

(6.4)

(6.5)
(6.6)
(6.7)

Moreover, if some wâˆ—, Î±âˆ—, Î²âˆ— satisfy the KKT conditions, then it is also a solution to the primal and dual
problems.

We draw attention to Equation (6.5), which is called the KKT dual
complementarity condition. Speciï¬cally, it implies that if Î±âˆ—
i > 0, then
gi(wâˆ—) = 0. (I.e., the â€œgi(w) â‰¤ 0â€ constraint is active, meaning it holds with
equality rather than with inequality.) Later on, this will be key for showing
that the SVM has only a small number of â€œsupport vectorsâ€; the KKT dual
complementarity condition will also give us our convergence test when we
talk about the SMO algorithm.

6.6 Optimal margin classiï¬ers: the dual form

(option reading)

Note: The equivalence of optimization problem (6.8) and the optimization
problem (6.12), and the relationship between the primary and dual variables
in equation (6.10) are the most important take home messages of this section.

Previously, we posed the following (primal) optimization problem for ï¬nd-

ing the optimal margin classiï¬er:

minw,b

1
2

||w||2

s.t. y(i)(wT x(i) + b) â‰¥ 1,

i = 1, . . . , n

We can write the constraints as

gi(w) = âˆ’y(i)(wT x(i) + b) + 1 â‰¤ 0.

(6.8)

69

We have one such constraint for each training example. Note that from the
KKT dual complementarity condition, we will have Î±i > 0 only for the train-
ing examples that have functional margin exactly equal to one (i.e., the ones
corresponding to constraints that hold with equality, gi(w) = 0). Consider
the ï¬gure below, in which a maximum margin separating hyperplane is shown
by the solid line.

The points with the smallest margins are exactly the ones closest to the
decision boundary; here, these are the three points (one negative and two pos-
itive examples) that lie on the dashed lines parallel to the decision boundary.
Thus, only three of the Î±iâ€™sâ€”namely, the ones corresponding to these three
training examplesâ€”will be non-zero at the optimal solution to our optimiza-
tion problem. These three points are called the support vectors in this
problem. The fact that the number of support vectors can be much smaller
than the size the training set will be useful later.

Letâ€™s move on. Looking ahead, as we develop the dual form of the prob-
lem, one key idea to watch out for is that weâ€™ll try to write our algorithm
in terms of only the inner product (cid:104)x(i), x(j)(cid:105) (think of this as (x(i))T x(j))
between points in the input feature space. The fact that we can express our
algorithm in terms of these inner products will be key when we apply the
kernel trick.

When we construct the Lagrangian for our optimization problem we have:

L(w, b, Î±) =

n
(cid:88)

||w||2 âˆ’

(cid:2)y(i)(wT x(i) + b) âˆ’ 1(cid:3) .

Î±i

(6.9)

1
2

i=1
Note that thereâ€™re only â€œÎ±iâ€ but no â€œÎ²iâ€ Lagrange multipliers, since the
problem has only inequality constraints.

70

Letâ€™s ï¬nd the dual form of the problem. To do so, we need to ï¬rst
minimize L(w, b, Î±) with respect to w and b (for ï¬xed Î±), to get Î¸D, which
weâ€™ll do by setting the derivatives of L with respect to w and b to zero. We
have:

âˆ‡wL(w, b, Î±) = w âˆ’

Î±iy(i)x(i) = 0

n
(cid:88)

This implies that

i=1

w =

n
(cid:88)

i=1

Î±iy(i)x(i).

As for the derivative with respect to b, we obtain

âˆ‚
âˆ‚b

L(w, b, Î±) =

n
(cid:88)

i=1

Î±iy(i) = 0.

(6.10)

(6.11)

If we take the deï¬nition of w in Equation (6.10) and plug that back into

the Lagrangian (Equation 6.9), and simplify, we get

L(w, b, Î±) =

n
(cid:88)

i=1

Î±i âˆ’

1
2

n
(cid:88)

i,j=1

y(i)y(j)Î±iÎ±j(x(i))T x(j) âˆ’ b

n
(cid:88)

i=1

Î±iy(i).

But from Equation (6.11), the last term must be zero, so we obtain

L(w, b, Î±) =

n
(cid:88)

i=1

Î±i âˆ’

1
2

n
(cid:88)

i,j=1

y(i)y(j)Î±iÎ±j(x(i))T x(j).

Recall that we got to the equation above by minimizing L with respect to
w and b. Putting this together with the constraints Î±i â‰¥ 0 (that we always
had) and the constraint (6.11), we obtain the following dual optimization
problem:

maxÎ± W (Î±) =

n
(cid:88)

Î±i âˆ’

n
(cid:88)

y(i)y(j)Î±iÎ±j(cid:104)x(i), x(j)(cid:105).

(6.12)

1
2

i=1
i = 1, . . . , n

i,j=1

s.t. Î±i â‰¥ 0,
n
(cid:88)

Î±iy(i) = 0,

i=1

You should also be able to verify that the conditions required for pâˆ— = dâˆ—
and the KKT conditions (Equations 6.3â€“6.7) to hold are indeed satisï¬ed in

71

our optimization problem. Hence, we can solve the dual in lieu of solving
the primal problem. Speciï¬cally, in the dual problem above, we have a
maximization problem in which the parameters are the Î±iâ€™s. Weâ€™ll talk later
about the speciï¬c algorithm that weâ€™re going to use to solve the dual problem,
but if we are indeed able to solve it (i.e., ï¬nd the Î±â€™s that maximize W (Î±)
subject to the constraints), then we can use Equation (6.10) to go back and
ï¬nd the optimal wâ€™s as a function of the Î±â€™s. Having found wâˆ—, by considering
the primal problem, it is also straightforward to ï¬nd the optimal value for
the intercept term b as

bâˆ— = âˆ’

maxi:y(i)=âˆ’1 wâˆ—T x(i) + mini:y(i)=1 wâˆ—T x(i)
2

.

(6.13)

(Check for yourself that this is correct.)

Before moving on, letâ€™s also take a more careful look at Equation (6.10),
which gives the optimal value of w in terms of (the optimal value of) Î±.
Suppose weâ€™ve ï¬t our modelâ€™s parameters to a training set, and now wish to
make a prediction at a new point input x. We would then calculate wT x + b,
and predict y = 1 if and only if this quantity is bigger than zero. But
using (6.10), this quantity can also be written:

wT x + b =

(cid:33)T

Î±iy(i)x(i)

x + b

(cid:32) n

(cid:88)

i=1

=

n
(cid:88)

i=1

Î±iy(i)(cid:104)x(i), x(cid:105) + b.

(6.14)

(6.15)

Hence, if weâ€™ve found the Î±iâ€™s, in order to make a prediction, we have to
calculate a quantity that depends only on the inner product between x and
the points in the training set. Moreover, we saw earlier that the Î±iâ€™s will all
be zero except for the support vectors. Thus, many of the terms in the sum
above will be zero, and we really need to ï¬nd only the inner products between
x and the support vectors (of which there is often only a small number) in
order calculate (6.15) and make our prediction.

By examining the dual form of the optimization problem, we gained sig-
niï¬cant insight into the structure of the problem, and were also able to write
the entire algorithm in terms of only inner products between input feature
vectors. In the next section, we will exploit this property to apply the ker-
nels to our classiï¬cation problem. The resulting algorithm, support vector
machines, will be able to eï¬ƒciently learn in very high dimensional spaces.

72

6.7 Regularization and the non-separable case

(optional reading)

The derivation of the SVM as presented so far assumed that the data is
linearly separable. While mapping data to a high dimensional feature space
via Ï† does generally increase the likelihood that the data is separable, we
canâ€™t guarantee that it always will be so. Also, in some cases it is not clear
that ï¬nding a separating hyperplane is exactly what weâ€™d want to do, since
that might be susceptible to outliers. For instance, the left ï¬gure below
shows an optimal margin classiï¬er, and when a single outlier is added in the
upper-left region (right ï¬gure), it causes the decision boundary to make a
dramatic swing, and the resulting classiï¬er has a much smaller margin.

To make the algorithm work for non-linearly separable datasets as well
as be less sensitive to outliers, we reformulate our optimization (using (cid:96)1
regularization) as follows:

minÎ³,w,b

1
2

||w||2 + C

n
(cid:88)

i=1

Î¾i

s.t. y(i)(wT x(i) + b) â‰¥ 1 âˆ’ Î¾i,

i = 1, . . . , n

Î¾i â‰¥ 0,

i = 1, . . . , n.

Thus, examples are now permitted to have (functional) margin less than 1,
and if an example has functional margin 1 âˆ’ Î¾i (with Î¾ > 0), we would pay
a cost of the objective function being increased by CÎ¾i. The parameter C
controls the relative weighting between the twin goals of making the ||w||2
small (which we saw earlier makes the margin large) and of ensuring that
most examples have functional margin at least 1.

As before, we can form the Lagrangian:

L(w, b, Î¾, Î±, r) =

1
2

wT w + C

n
(cid:88)

n
(cid:88)

Î¾i âˆ’

i=1

i=1

(cid:2)y(i)(xT w + b) âˆ’ 1 + Î¾i

(cid:3) âˆ’

Î±i

73

n
(cid:88)

i=1

riÎ¾i.

Here, the Î±iâ€™s and riâ€™s are our Lagrange multipliers (constrained to be â‰¥ 0).
We wonâ€™t go through the derivation of the dual again in detail, but after
setting the derivatives with respect to w and b to zero as before, substituting
them back in, and simplifying, we obtain the following dual form of the
problem:

maxÎ± W (Î±) =

n
(cid:88)

Î±i âˆ’

1
2

n
(cid:88)

i,j=1

y(i)y(j)Î±iÎ±j(cid:104)x(i), x(j)(cid:105)

i=1
s.t. 0 â‰¤ Î±i â‰¤ C,

i = 1, . . . , n

n
(cid:88)

i=1

Î±iy(i) = 0,

As before, we also have that w can be expressed in terms of the Î±iâ€™s as
given in Equation (6.10), so that after solving the dual problem, we can con-
tinue to use Equation (6.15) to make our predictions. Note that, somewhat
surprisingly, in adding (cid:96)1 regularization, the only change to the dual prob-
lem is that what was originally a constraint that 0 â‰¤ Î±i has now become
0 â‰¤ Î±i â‰¤ C. The calculation for bâˆ— also has to be modiï¬ed (Equation 6.13 is
no longer valid); see the comments in the next section/Plattâ€™s paper.

Also, the KKT dual-complementarity conditions (which in the next sec-
tion will be useful for testing for the convergence of the SMO algorithm)
are:

Î±i = 0 â‡’ y(i)(wT x(i) + b) â‰¥ 1
Î±i = C â‡’ y(i)(wT x(i) + b) â‰¤ 1
0 < Î±i < C â‡’ y(i)(wT x(i) + b) = 1.

(6.16)
(6.17)
(6.18)

Now, all that remains is to give an algorithm for actually solving the dual

problem, which we will do in the next section.

6.8 The SMO algorithm (optional reading)

The SMO (sequential minimal optimization) algorithm, due to John Platt,
gives an eï¬ƒcient way of solving the dual problem arising from the derivation

74

of the SVM. Partly to motivate the SMO algorithm, and partly because itâ€™s
interesting in its own right, letâ€™s ï¬rst take another digression to talk about
the coordinate ascent algorithm.

6.8.1 Coordinate ascent

Consider trying to solve the unconstrained optimization problem

max
Î±

W (Î±1, Î±2, . . . , Î±n).

Here, we think of W as just some function of the parameters Î±iâ€™s, and for now
ignore any relationship between this problem and SVMs. Weâ€™ve already seen
two optimization algorithms, gradient ascent and Newtonâ€™s method. The
new algorithm weâ€™re going to consider here is called coordinate ascent:

Loop until convergence: {

For i = 1, . . . , n, {

Î±i := arg max Ë†Î±i W (Î±1, . . . , Î±iâˆ’1, Ë†Î±i, Î±i+1, . . . , Î±n).

}

}

Thus, in the innermost loop of this algorithm, we will hold all the variables
except for some Î±i ï¬xed, and reoptimize W with respect to just the parameter
Î±i. In the version of this method presented here, the inner-loop reoptimizes
the variables in order Î±1, Î±2, . . . , Î±n, Î±1, Î±2, . . .. (A more sophisticated version
might choose other orderings; for instance, we may choose the next variable
to update according to which one we expect to allow us to make the largest
increase in W (Î±).)

When the function W happens to be of such a form that the â€œarg maxâ€
in the inner loop can be performed eï¬ƒciently, then coordinate ascent can be
a fairly eï¬ƒcient algorithm. Hereâ€™s a picture of coordinate ascent in action:

75

The ellipses in the ï¬gure are the contours of a quadratic function that
we want to optimize. Coordinate ascent was initialized at (2, âˆ’2), and also
plotted in the ï¬gure is the path that it took on its way to the global maximum.
Notice that on each step, coordinate ascent takes a step thatâ€™s parallel to one
of the axes, since only one variable is being optimized at a time.

6.8.2 SMO

We close oï¬€ the discussion of SVMs by sketching the derivation of the SMO
algorithm.

Hereâ€™s the (dual) optimization problem that we want to solve:

maxÎ± W (Î±) =
