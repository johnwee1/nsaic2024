ptions about how the training and test
set are collected, then we can make some progress.
The train and test data are generated by a probability distribution over datasets
called the data generating process. We typically make a set of assumptions
known collectively as the i.i.d. assumptions. These assumptions are that the
examples in each dataset are independent from each other, and that the train
set and test set are identically distributed, drawn from the same probability
distribution as each other. This assumption allows us to describe the data generating process with a probability distribution over a single example. The same
distribution is then used to generate every train example and every test example.
We call that shared underlying distribution the data generating distribution,
denoted pdata . This probabilistic framework and the i.i.d. assumptions allow us to
mathematically study the relationship between training error and test error.
One immediate connection we can observe between the training and test error
is that the expected training error of a randomly selected model is equal to the
expected test error of that model. Suppose we have a probability distribution
p(x, y) and we sample from it repeatedly to generate the train set and the test
set. For some ï¬?xed value w, the expected training set error is exactly the same as
the expected test set error, because both expectations are formed using the same
dataset sampling process. The only diï¬€erence between the two conditions is the
name we assign to the dataset we sample.
Of course, when we use a machine learning algorithm, we do not ï¬?x the
parameters ahead of time, then sample both datasets. We sample the training set,
then use it to choose the parameters to reduce training set error, then sample the
test set. Under this process, the expected test error is greater than or equal to
the expected value of training error. The factors determining how well a machine
learning algorithm will perform are its ability to:
1. Make the training error small.
2. Make the gap between training and test error small.
These two factors correspond to the two central challenges in machine learning:
underï¬?tting and overï¬?tting . Underï¬?tting occurs when the model is not able to
obtain a suï¬ƒciently low error value on the training set. Overï¬?tting occurs when
the gap between the training error and test error is too large.
We can control whether a model is more likely to overï¬?t or underï¬?t by altering
its capacity. Informally, a modelâ€™s capacity is its ability to ï¬?t a wide variety of
111

CHAPTER 5. MACHINE LEARNING BASICS

functions. Models with low capacity may struggle to ï¬?t the training set. Models
with high capacity can overï¬?t by memorizing properties of the training set that do
not serve them well on the test set.
One way to control the capacity of a learning algorithm is by choosing its
hypothesis space, the set of functions that the learning algorithm is allowed to
select as being the solution. For example, the linear regression algorithm has the
set of all linear functions of its input as its hypothesis space. We can generalize
linear regression to include polynomials, rather than just linear functions, in its
hypothesis space. Doing so increases the modelâ€™s capacity.
A polynomial of degree one gives us the linear regression model with which we
are already familiar, with prediction
yÌ‚ = b + wx.

(5.15)

By introducing x2 as another feature provided to the linear regression model, we
can learn a model that is quadratic as a function of x:
yÌ‚ = b + w 1x + w2x2 .

(5.16)

Though this model implements a quadratic function of its input, the output is
still a linear function of the parameters, so we can still use the normal equations
to train the model in closed form. We can continue to add more powers of x as
additional features, for example to obtain a polynomial of degree 9:
yÌ‚ = b +

9
î?˜

wixi.

(5.17)

i=1

Machine learning algorithms will generally perform best when their capacity
is appropriate for the true complexity of the task they need to perform and the
amount of training data they are provided with. Models with insuï¬ƒcient capacity
are unable to solve complex tasks. Models with high capacity can solve complex
tasks, but when their capacity is higher than needed to solve the present task they
may overï¬?t.
Figure 5.2 shows this principle in action. We compare a linear, quadratic
and degree-9 predictor attempting to ï¬?t a problem where the true underlying
function is quadratic. The linear function is unable to capture the curvature in
the true underlying problem, so it underï¬?ts. The degree-9 predictor is capable of
representing the correct function, but it is also capable of representing inï¬?nitely
many other functions that pass exactly through the training points, because we
112

CHAPTER 5. MACHINE LEARNING BASICS

have more parameters than training examples. We have little chance of choosing
a solution that generalizes well when so many wildly diï¬€erent solutions exist. In
this example, the quadratic model is perfectly matched to the true structure of
the task so it generalizes well to new data.

î?¸î€°

î??î?¶î?¥î?²î?¦î?©î?´î?´î?©î?®î?§

î?¹

î??î?°î?°î?²î?¯î?°î?²î?©î?¡î?´î?¥î€ î?£î?¡î?°î?¡î?£î?©î?´î?¹

î?¹

î?¹

î?•î?®î?¤î?¥î?²î?¦î?©î?´î?´î?©î?®î?§

î?¸î€°

î?¸î€°

Figure 5.2: We ï¬?t three models to this example training set. The training data was
generated synthetically, by randomly sampling x values and choosing y deterministically
by evaluating a quadratic function. (Left)A linear function ï¬?t to the data suï¬€ers from
underï¬?ttingâ€”it cannot capture the curvature that is present in the data. (Center)A
quadratic function ï¬?t to the data generalizes well to unseen points. It does not suï¬€er from
a signiï¬?cant amount of overï¬?tting or underï¬?tting. (Right)A polynomial of degree 9 ï¬?t to
the data suï¬€ers from overï¬?tting. Here we used the Moore-Penrose pseudoinverse to solve
the underdetermined normal equations. The solution passes through all of the training
points exactly, but we have not been lucky enough for it to extract the correct structure.
It now has a deep valley in between two training points that does not appear in the true
underlying function. It also increases sharply on the left side of the data, while the true
function decreases in this area.

So far we have described only one way of changing a modelâ€™s capacity: by
changing the number of input features it has, and simultaneously adding new
parameters associated with those features. There are in fact many ways of changing
a modelâ€™s capacity. Capacity is not determined only by the choice of model. The
model speciï¬?es which family of functions the learning algorithm can choose from
when varying the parameters in order to reduce a training objective. This is called
the representational capacity of the model. In many cases, ï¬?nding the best
function within this family is a very diï¬ƒcult optimization problem. In practice,
the learning algorithm does not actually ï¬?nd the best function, but merely one
that signiï¬?cantly reduces the training error. These additional limitations, such as
113

CHAPTER 5. MACHINE LEARNING BASICS

the imperfection of the optimization algorithm, mean that the learning algorithmâ€™s
eï¬€ective capacity may be less than the representational capacity of the model
family.
Our modern ideas about improving the generalization of machine learning
models are reï¬?nements of thought dating back to philosophers at least as early
as Ptolemy. Many early scholars invoke a principle of parsimony that is now
most widely known as Occamâ€™s razor (c. 1287-1347). This principle states that
among competing hypotheses that explain known observations equally well, one
should choose the â€œsimplestâ€? one. This idea was formalized and made more precise
in the 20th century by the founders of statistical learning theory (Vapnik and
Chervonenkis, 1971; Vapnik, 1982; Blumer et al., 1989; Vapnik, 1995).
Statistical learning theory provides various means of quantifying model capacity.
Among these, the most well-known is the Vapnik-Chervonenkis dimension, or
VC dimension. The VC dimension measures the capacity of a binary classiï¬?er. The
VC dimension is deï¬?ned as being the largest possible value of m for which there
exists a training set of m diï¬€erent x points that the classiï¬?er can label arbitrarily.
Quantifying the capacity of the model allows statistical learning theory to
make quantitative predictions. The most important results in statistical learning
theory show that the discrepancy between training error and generalization error
is bounded from above by a quantity that grows as the model capacity grows but
shrinks as the number of training examples increases (Vapnik and Chervonenkis,
1971; Vapnik, 1982; Blumer et al., 1989; Vapnik, 1995). These bounds provide
intellectual justiï¬?cation that machine learning algorithms can work, but they are
rarely used in practice when working with deep learning algorithms. This is in
part because the bounds are often quite loose and in part because it can be quite
diï¬ƒcult to determine the capacity of deep learning algorithms. The problem of
determining the capacity of a deep learning model is especially diï¬ƒcult because the
eï¬€ective capacity is limited by the capabilities of the optimization algorithm, and
we have little theoretical understanding of the very general non-convex optimization
problems involved in deep learning.
We must remember that while simpler functions are more likely to generalize
(to have a small gap between training and test error) we must still choose a
suï¬ƒciently complex hypothesis to achieve low training error. Typically, training
error decreases until it asymptotes to the minimum possible error value as model
capacity increases (assuming the error measure has a minimum value). Typically,
generalization error has a U-shaped curve as a function of model capacity. This is
illustrated in ï¬?gure 5.3.
To reach the most extreme case of arbitrarily high capacity, we introduce
114

CHAPTER 5. MACHINE LEARNING BASICS

Training error
Generalization error

Error

Underï¬?tting zone Overï¬?tting zone

Generalization gap
0

Optimal Capacity
Capacity

Figure 5.3: Typical relationship between capacity and error. Training and test error
behave diï¬€erently. At the left end of the graph, training error and generalization error
are both high. This is the underï¬?tting regime. As we increase capacity, training error
decreases, but the gap between training and generalization error increases. Eventually,
the size of this gap outweighs the decrease in training error, and we enter theoverï¬?tting
regime, where capacity is too large, above the optimal capacity.

the concept of non-parametric models. So far, we have seen only parametric
models, such as linear regression. Parametric models learn a function described
by a parameter vector whose size is ï¬?nite and ï¬?xed before any data is observed.
Non-parametric models have no such limitation.
Sometimes, non-parametric models are just theoretical abstractions (such as
an algorithm that searches over all possible probability distributions) that cannot
be implemented in practice. However, we can also design practical non-parametric
models by making their complexity a function of the training set size. One example
of such an algorithm is nearest neighbor regression. Unlike linear regression,
which has a ï¬?xed-length vector of weights, the nearest neighbor regression model
simply stores the X and y from the training set. When asked to classify a test
point x, the model looks up the nearest entry in the training set and returns the
associated regression target. In other words, yÌ‚ = yi where i = arg min ||X i,: âˆ’ x||22.
The algorithm can also be generalized to distance metrics other than the L2 norm,
such as learned distance metrics (Goldberger et al., 2005). If the algorithm is
allowed to break ties by averaging the yi values for all Xi,: that are tied for nearest,
then this algorithm is able to achieve the minimum possible training error (which
might be greater than zero, if two identical inputs are associated with diï¬€erent
outputs) on any regression dataset.
Finally, we can also create a non-parametric learning algorithm by wrapping a
115

CHAPTER 5. MACHINE LEARNING BASICS

parametric learning algorithm inside another algorithm that increases the number
of parameters as needed. For example, we could imagine an outer loop of learning
that changes the degree of the polynomial learned by linear regression on top of a
polynomial expansion of the input.
The ideal model is an oracle that simply knows the true probability distribution
that generates the data. Even such a model will still incur some error on many
problems, because there may still be some noise in the distribution. In the case
of supervised learning, the mapping from x to y may be inherently stochastic,
or y may be a deterministic function that involves other variables besides those
included in x. The error incurred by an oracle making predictions from the true
distribution p(x, y) is called the Bayes error.
Training and generalization error vary as the size of the training set varies.
Expected generalization error can never increase as the number of training examples
increases. For non-parametric models, more data yields better generalization until
the best possible error is achieved. Any ï¬?xed parametric model with less than
optimal capacity will asymptote to an error value that exceeds the Bayes error. See
ï¬?gure 5.4 for an illustration. Note that it is possible for the model to have optimal
capacity and yet still have a large gap between training and generalization error.
In this situation, we may be able to reduce this gap by gathering more training
examples.

5.2.1

The No Free Lunch Theorem

Learning theory claims that a machine learning algorithm can generalize well from
a ï¬?nite training set of examples. This seems to contradict some basic principles of
logic. Inductive reasoning, or inferring general rules from a limited set of examples,
is not logically valid. To logically infer a rule describing every member of a set,
one must have information about every member of that set.
In part, machine learning avoids this problem by oï¬€ering only probabilistic rules,
rather than the entirely certain rules used in purely logical reasoning. Machine
learning promises to ï¬?nd rules that are probably correct about most members of
the set they concern.
Unfortunately, even this does not resolve the entire problem. The no free
lunch theorem for machine learning (Wolpert, 1996) states that, averaged over
all possible data generating distributions, every classiï¬?cation algorithm has the
same error rate when classifying previously unobserved points. In other words,
in some sense, no machine learning algorithm is universally any better than any
other. The most sophisticated algorithm we can conceive of has the same average
116

CHAPTER 5. MACHINE LEARNING BASICS

î€³î€®î€µ

î?‚î?¡î?¹î?¥î?³î€ î?¥î?²î?²î?¯î?²
î?”î?²î?¡î?©î?®î€ î€¨î?±î?µî?¡î?¤î?²î?¡î?´î?©î?£î€©

î?…î?²î?²î?¯î?²î€ î€¨î??î?“î?…î€©

î€³î€®î€°
î€²î€®î€µ

î?”î?¥î?³î?´î€ î€¨î?±î?µî?¡î?¤î?²î?¡î?´î?©î?£î€©
î?”î?¥î?³î?´î€ î€¨î?¯î?°î?´î?©î?­î?¡î?¬î€ î?£î?¡î?°î?¡î?£î?©î?´î?¹î€©
î?”î?²î?¡î?©î?®î€ î€¨î?¯î?°î?´î?©î?­î?¡î?¬î€ î?£î?¡î?°î?¡î?£î?©î?´î?¹î€©

î€²î€®î€°
î€±î€®î€µ
î€±î€®î€°
î€°î€®î€µ
î€°î€®î€°
î€°
î€±î€°

î€±

î€±î€