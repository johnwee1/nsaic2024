n the feature weight gives an
indication of how associated the feature is with the class.

21.8 Lexicon-based methods for Entity-Centric Affect

What if we want to get an affect score not for an entire document, but for a particular
entity in the text? The entity-centric method of Field and Tsvetkov (2019) combines
affect lexicons with contextual embeddings to assign an affect score to an entity in
text. In the context of affect about people, they relabel the Valence/Arousal/Domi-
nance dimension as Sentiment/Agency/Power. The algorithm ﬁrst trains classiﬁers
to map embeddings to scores:

1. For each word w in the training corpus:

(a) Use off-the-shelf pretrained encoders (like BERT) to extract a contextual
embedding e for each instance of the word. No additional ﬁne-tuning is
done.

(b) Average over the e embeddings of each instance of w to obtain a single

embedding vector for one training point w.

(c) Use the NRC VAD Lexicon to get S, A, and P scores for w.

2. Train (three) regression models on all words w to predict V, A, D scores from

a word’s average embedding.

Now given an entity mention m in a text, we assign affect scores as follows:

1. Use the same pretrained LM to get contextual embeddings for m in context.
2. Feed this embedding through the 3 regression models to get S, A, P scores for

the entity.

This results in a (S,A,P) tuple for a given entity mention; To get scores for the rep-
resentation of an entity in a complete document, we can run coreference resolution
and average the (S,A,P) scores for all the mentions. Fig. 21.13 shows the scores
from their algorithm for characters from the movie The Dark Knight when run on
Wikipedia plot summary texts with gold coreference.

21.9 Connotation Frames

connotation
frame

The lexicons we’ve described so far deﬁne a word as a point in affective space. A
connotation frame, by contrast, is a lexicon that incorporates a richer kind of gram-
matical structure, by combining affective lexicons with the frame semantic lexicons
of Chapter 24. The basic insight of connotation frame lexicons is that a predicate
like a verb expresses connotations about the verb’s arguments (Rashkin et al. 2016,
Rashkin et al. 2017).

Consider sentences like:

(21.15) Country A violated the sovereignty of Country B

478 CHAPTER 21

• LEXICONS FOR SENTIMENT, AFFECT, AND CONNOTATION

Figure 21.13 Power (dominance), sentiment (valence) and agency (arousal) for characters
in the movie The Dark Knight computed from embeddings trained on the NRC VAD Lexicon.
Note the protagonist (Batman) and the antagonist (the Joker) have high power and agency
scores but differ in sentiment, while the love interest Rachel has low power and agency but
high sentiment.

(21.16) the teenager ... survived the Boston Marathon bombing”

By using the verb violate in (21.15), the author is expressing their sympathies with
Country B, portraying Country B as a victim, and expressing antagonism toward
the agent Country A. By contrast, in using the verb survive, the author of (21.16) is
expressing that the bombing is a negative experience, and the subject of the sentence,
the teenager, is a sympathetic character. These aspects of connotation are inherent
in the meaning of the verbs violate and survive, as shown in Fig. 21.14.

(a)

(b)

Figure 21.14 Connotation frames for survive and violate. (a) For survive, the writer and reader have positive
sentiment toward Role1, the subject, and negative sentiment toward Role2, the direct object. (b) For violate, the
writer and reader have positive sentiment instead toward Role2, the direct object.

The connotation frame lexicons of Rashkin et al. (2016) and Rashkin et al.
(2017) also express other connotative aspects of the predicate toward each argu-
ment, including the effect (something bad happened to x) value: (x is valuable), and
mental state: (x is distressed by the event). Connotation frames can also mark the
power differential between the arguments (using the verb implore means that the
theme argument has greater power than the agent), and the agency of each argument
(waited is low agency). Fig. 21.15 shows a visualization from Sap et al. (2017).

Connotation frames can be built by hand (Sap et al., 2017), or they can be learned
by supervised learning (Rashkin et al., 2016), for example using hand-labeled train-

Power ScoreweaklyRachelDentGordanBatmanJokerpowerfullySentiment ScorenegativeJokerDentGordanRachelBatmanpositiveAgency ScoredullDentGordanRachelBatmanJokerscaryFigure1:Power,sentiment,andagencyscoresforchar-actersinTheDarkNightaslearnedthroughtheregres-sionmodelwithELMoembeddings.Scoresgenerallyalignwithcharacterarchetypes,i.e.theantagonisthasthelowestsentimentscore.menthaveresultedinhiseffectiveremovalfromtheindustry.Whilearticlesaboutthe#MeToomovementportraymenlikeWeinsteinasunpow-erful,wecanspeculatethatthecorporausedtotrainELMoandBERTportraythemaspowerful.Thus,inacorpuswheretraditionalpowerroleshavebeeninverted,theembeddingsextractedfromELMoandBERTperformworsethanran-dom,astheyarebiasedtowardsthepowerstruc-turesinthedatatheyaretrainedon.Furtherev-idenceofthisexistsintheperformanceoftheBERT-maskedembeddings-whereastheseem-beddingsgenerallycapturepowerpoorlyascom-paredtotheunmaskedembeddings(Table2),theyoutperformtheunmaskedembeddingsonthistask,andevenoutperformthefrequencybaselineinonesetting.Nevertheless,theydonotoutper-formFieldetal.(2019),likelybecausetheydonotcaptureaffectinformationaswellastheunmaskedembeddings(Table2).4.3QualitativeDocument-levelAnalysisFinally,wequalitativelyanalyzehowwellourmethodcapturesaffectdimensionsbyanalyzingsingledocumentsindetail.Weconductthisanal-ysisinadomainwhereweexpectentitiestofulﬁlltraditionalpowerrolesandwhereentityportray-alsareknown.FollowingBammanetal.(2013),weanalyzetheWikipediaplotsummaryofthemovieTheDarkKnight,7focusingonBatman(protagonist),8theJoker(antagonist),JimGordan(lawenforcementofﬁcer,allytoBatman),Har-7http://bit.ly/2XmhRDR8WeconsiderBatman/BruceWaynetobethesameentity.Power ScoreweaklyRachelJokerDentGordanBatmanpowerfullySentiment ScorenegativeJokerGordanBatmanDentRachelpositiveAgency ScoredullRachelDentGordanBatmanJokerscaryFigure2:Power,sentiment,andagencyscoresforchar-actersinTheDarkNightaslearnedthroughASPwithELMoembeddings.Thesescoresreﬂectthesamepat-ternsastheregressionmodelwithgreaterseparationbetweencharacters.veyDent(allytoBatmanwhoturnsevil)andRachelDawes(primaryloveinterest).Tofacil-itateextractingexamplesentences,wescoreeachinstanceoftheseentitiesinthenarrativeseparatelyandaverageacrossinstancestoobtainanentityscoreforthedocument.9Tomaximizeourdatabycapturingeverymentionofanentity,weper-formco-referenceresolutionbyhand.Addition-ally,basedonourresultsfromTable3aswellastheuseofWikipediadataintrainingtheELMomodel(Petersetal.,2018),weuseELMoembed-dingsforouranalysis.Figures1and2showresults.Forrefer-ence,weshowtheentityscoresascomparedtoonepolaroppositepairidentiﬁedbyASP.BoththeregressionmodelandASPshowsimilarpat-terns.Batmanhashighpower,whileRachelhaslowpower.Additionally,theJokerisassociatedwiththemostnegativesentiment,butthehigh-estagency.Throughouttheplotsummary,themovieprogressesbytheJokertakinganaggres-siveactionandtheothercharactersresponding.WecanseethisdynamicreﬂectedintheJoker’sproﬁlescore,asahigh-powered,high-agency,low-sentimentcharacter,whoistheprimaryplot-driver.Ingeneral,ASPshowsagreaterseparationbetweencharactersthantheregressionmodel.WehypothesizethatthisoccursbecauseASPisolatesthedimensionsofinterest,whiletheregressionap-proachcapturesotherconfounds,suchasthathu-9Whenweusedthisaveragingmetricinotherevaluations,wefoundnosigniﬁcantchangeinresults.Thus,inothersce-narios,wecomputescoresoveraveragedembeddings,ratherthanaveragingscoresseparatelycomputedforeachembed-dingtoreducecomputationallycomplexity.WriterRole1Role2Role1 is asympathetic victimThere issome typeof hardshipReader+_+__S(writer→role1)S(writer→role2)Connotation Frame for “Role1 survives Role2” S(role1→role2)WriterRole1Role2Role1 is the antagonistRole2 is asympathetic victimReader+_+__S(writer→role1)S(writer→role2)Connotation Frame for “Role1 violates Role2” S(role1→role2)21.10

• SUMMARY

479

Figure 21.15 The connotation frames of Sap et al. (2017), showing that the verb implore
implies the agent has lower power than the theme (in contrast, say, with a verb like demanded),
and showing the low level of agency of the subject of waited. Figure from Sap et al. (2017).

ing data to supervise classiﬁers for each of the individual relations, e.g., whether
S(writer
Role1) is + or -, and then improving accuracy via global constraints
→
across all relations.

21.10 Summary

• Many kinds of affective states can be distinguished, including emotions, moods,
attitudes (which include sentiment), interpersonal stance, and personality.

• Emotion can be represented by ﬁxed atomic units often called basic emo-
tions, or as points in space deﬁned by dimensions like valence and arousal.

• Words have connotational aspects related to these affective states, and this

connotational aspect of word meaning can be represented in lexicons.

• Affective lexicons can be built by hand, using crowd sourcing to label the

affective content of each word.

• Lexicons can be built with semi-supervised, bootstrapping from seed words

using similarity metrics like embedding cosine.

• Lexicons can be learned in a fully supervised manner, when a convenient
training signal can be found in the world, such as ratings assigned by users on
a review site.

• Words can be assigned weights in a lexicon by using various functions of word
counts in training texts, and ratio metrics like log odds ratio informative
Dirichlet prior.

• Affect can be detected, just like sentiment, by using standard supervised text
classiﬁcation techniques, using all the words or bigrams in a text as features.
Additional features can be drawn from counts of words in lexicons.

• Lexicons can also be used to detect affect in a rule-based classiﬁer by picking

the simple majority sentiment based on counts of words in each lexicon.

• Connotation frames express richer relations of affective meaning that a pred-

icate encodes about its arguments.

AGENTTHEMEpower(AG < TH)VERBimploreHe implored the tribunal to show mercy.The princess waited for her prince.AGENTTHEMEagency(AG) = -VERBwaitFigure2:Theformalnotationoftheconnotationframesofpowerandagency.Theﬁrstexampleshowstherelativepowerdifferentialimpliedbytheverb“implored”,i.e.,theagent(“he”)isinapositionoflesspowerthanthetheme(“thetri-bunal”).Incontrast,“Hedemandedthetribunalshowmercy”impliesthattheagenthasauthorityoverthetheme.Thesecondexampleshowsthelowlevelofagencyimpliedbytheverb“waited”.interactivedemowebsiteofourﬁndings(seeFig-ure5intheappendixforascreenshot).2Further-more,aswillbeseeninSection4.1,connotationframesoffernewinsightsthatcomplementandde-viatefromthewell-knownBechdeltest(Bechdel,1986).Inparticular,weﬁndthathigh-agencywomenthroughthelensofconnotationframesarerareinmodernﬁlms.Itis,inpart,becausesomemovies(e.g.,SnowWhite)accidentallypasstheBechdeltestandalsobecauseevenmovieswithstrongfemalecharactersarenotentirelyfreefromthedeeplyingrainedbiasesinsocialnorms.2ConnotationFramesofPowerandAgencyWecreatetwonewconnotationrelations,powerandagency(examplesinFigure3),asanexpan-sionoftheexistingconnotationframelexicons.3ThreeAMTcrowdworkersannotatedtheverbswithplaceholderstoavoidgenderbiasinthecon-text(e.g.,XrescuedY;anexampletaskisshownintheappendixinFigure7).Wedeﬁnetheanno-tatedconstructsasfollows:PowerDifferentialsManyverbsimplytheau-thoritylevelsoftheagentandthemerelativeto2http://homes.cs.washington.edu/˜msap/movie-bias/.3Thelexiconsandademoareavailableathttp://homes.cs.washington.edu/˜msap/movie-bias/.power(AG<TH)power(AG>TH)agency(AG)= agency(AG)=+Figure3:Sampleverbsintheconnotationframeswithhighannotatoragreement.Sizeisindicativeofverbfrequencyinourcorpus(bigger=morefrequent),colordifferencesareonlyforlegibility.oneanother.Forexample,iftheagent“dom-inates”thetheme(denotedaspower(AG>TH)),thentheagentisimpliedtohavealevelofcontroloverthetheme.Alternatively,iftheagent“hon-ors”thetheme(denotedaspower(AG<TH)),thewriterimpliesthatthethemeismoreimportantorauthoritative.WeusedAMTcrowdsourcingtola-bel1700transitiveverbsforpowerdifferentials.Withthreeannotatorsperverb,theinter-annotatoragreementis0.34(Krippendorff’s↵).AgencyTheagencyattributedtotheagentoftheverbdenoteswhethertheactionbeingdescribedimpliesthattheagentispowerful,decisive,andcapableofpushingforwardtheirownstoryline.Forexample,apersonwhoisdescribedas“ex-periencing”thingsdoesnotseemasactiveandde-cisiveassomeonewhoisdescribedas“determin-ing”things.AMTworkerslabeled2000transi-tiveverbsforimplyinghigh/moderate/lowagency(inter-annotatoragreementof0.27).Wedenotehighagencyasagency(AG)=+,andlowagencyasagency(AG)= .Pairwiseagreementsonahardconstraintare56%and51%forpowerandagency,respec-tively.Despitethis,agreementsreach96%and94%whenmoderatelabelsarecountedasagree-ingwitheitherhighorlowlabels,showingthatan-notatorsrarelystronglydisagreewithoneanother.SomecontributingfactorsinthelowerKAscoresincludethesubtletyofchoosingbetweenneutral480 CHAPTER 21

• LEXICONS FOR SENTIMENT, AFFECT, AND CONNOTATION

Bibliographical and Historical Notes

subjectivity

The idea of formally representing the subjective meaning of words began with Os-
good et al. (1957), the same pioneering study that ﬁrst proposed the vector space
model of meaning described in Chapter 6. Osgood et al. (1957) had participants rate
words on various scales, and ran factor analysis on the ratings. The most signiﬁcant
factor they uncovered was the evaluative dimension, which distinguished between
pairs like good/bad, valuable/worthless, pleasant/unpleasant. This work inﬂuenced
the development of early dictionaries of sentiment and affective meaning in the ﬁeld
of content analysis (Stone et al., 1966).

Wiebe (1994) began an inﬂuential line of work on detecting subjectivity in text,
beginning with the task of identifying subjective sentences and the subjective char-
acters who are described in the text as holding private states, beliefs or attitudes.
Learned sentiment lexicons such as the polarity lexicons of Hatzivassiloglou and
McKeown (1997) were shown to be a useful feature in subjectivity detection (Hatzi-
vassiloglou and Wiebe 2000, Wiebe 2000).

The term sentiment seems to have been introduced in 2001 by Das and Chen
(2001), to describe the task of measuring market sentiment by looking at the words in
stock trading message boards. In the same paper Das and Chen (2001) also proposed
the use of a sentiment lexicon. The list of words in the lexicon was created by
hand, but each word was assigned weights according to how much it discriminated
a particular class (say buy versus sell) by maximizing across-class variation and
minimizing within-class variation. The term sentiment, and the use of lexicons,
caught on quite quickly (e.g., inter alia, Turney 2002). Pang et al. (2002) ﬁrst showed
the power of using all the words without a sentiment lexicon; see also Wang and
Manning (2012).

Most of the semi-supervised methods we describe for extending sentiment dic-
tionaries drew on the early idea that synonyms and antonyms tend to co-occur in the
same sentence (Miller and Charles 1991, Justeson and Katz 1991, Riloff and Shep-
herd 1997). Other semi-supervised methods for learning cues to affective mean-
ing rely on information extraction techniques, like the AutoSlog pattern extractors
(Riloff and Wiebe, 2003). Graph bas