PART I
The Fundamentals of
Machine Learning

CHAPTER 1
The Machine Learning Landscape

When most people hear “Machine Learning,” they picture a robot: a dependable but‐
ler or a deadly Terminator, depending on who you ask. But Machine Learning is not
just  a  futuristic  fantasy;  it’s  already  here.  In  fact,  it  has  been  around  for  decades  in
some specialized applications, such as Optical Character Recognition (OCR). But the
first ML application that really became mainstream, improving the lives of hundreds
of millions of people, took over the world back in the 1990s: the spam filter. It’s not
exactly a self-aware Skynet, but it does technically qualify as Machine Learning (it has
actually learned so well that you seldom need to flag an email as spam anymore). It
was  followed  by  hundreds  of  ML  applications  that  now  quietly  power  hundreds  of
products and features that you use regularly, from better recommendations to voice
search.

Where  does  Machine  Learning  start  and  where  does  it  end?  What  exactly  does  it
mean for a machine to learn something? If I download a copy of Wikipedia, has my
computer  really  learned  something?  Is  it  suddenly  smarter?  In  this  chapter  we  will
start by clarifying what Machine Learning is and why you may want to use it.

Then,  before  we  set  out  to  explore  the  Machine  Learning  continent,  we  will  take  a
look at the map and learn about the main regions and the most notable landmarks:
supervised  versus  unsupervised  learning,  online  versus  batch  learning,  instance-
based versus model-based learning. Then we will look at the workflow of a typical ML
project,  discuss  the  main  challenges  you  may  face,  and  cover  how  to  evaluate  and
fine-tune a Machine Learning system.

This  chapter  introduces  a  lot  of  fundamental  concepts  (and  jargon)  that  every  data
scientist should know by heart. It will be a high-level overview (it’s the only chapter
without much code), all rather simple, but you should make sure everything is crystal
clear to you before continuing on to the rest of the book. So grab a coffee and let’s get
started!

1

If you already know all the Machine Learning basics, you may want
to skip directly to Chapter 2. If you are not sure, try to answer all
the questions listed at the end of the chapter before moving on.

What Is Machine Learning?
Machine  Learning  is  the  science  (and  art)  of  programming  computers  so  they  can
learn from data.

Here is a slightly more general definition:

[Machine  Learning  is  the]  field  of  study  that  gives  computers  the  ability  to  learn
without being explicitly programmed.

—Arthur Samuel, 1959

And a more engineering-oriented one:

A  computer  program  is  said  to  learn  from  experience  E  with  respect  to  some  task  T
and  some  performance  measure  P,  if  its  performance  on  T,  as  measured  by  P,
improves with experience E.

—Tom Mitchell, 1997

Your spam filter is a Machine Learning program that, given examples of spam emails
(e.g., flagged by users) and examples of regular (nonspam, also called “ham”) emails,
can learn to flag spam. The examples that the system uses to learn are called the train‐
ing set. Each training example is called a training instance (or sample). In this case, the
task T is to flag spam for new emails, the experience E is the training data, and the
performance  measure  P  needs  to  be  defined;  for  example,  you  can  use  the  ratio  of
correctly  classified  emails.  This  particular  performance  measure  is  called  accuracy,
and it is often used in classification tasks.

If you just download a copy of Wikipedia, your computer has a lot more data, but it is
not  suddenly  better  at  any  task.  Thus,  downloading  a  copy  of  Wikipedia  is  not
Machine Learning.

Why Use Machine Learning?
Consider how you would write a spam filter using traditional programming techni‐
ques (Figure 1-1):

1. First  you  would  consider  what  spam  typically  looks  like.  You  might  notice  that
some words or phrases (such as “4U,” “credit card,” “free,” and “amazing”) tend to
come up a lot in the subject line. Perhaps you would also notice a few other pat‐
terns in the sender’s name, the email’s body, and other parts of the email.

2 

| 

Chapter 1: The Machine Learning Landscape

2. You would write a detection algorithm for each of the patterns that you noticed,
and your program would flag emails as spam if a number of these patterns were
detected.

3. You would test your program and repeat steps 1 and 2 until it was good enough

to launch.

Figure 1-1. The traditional approach

Since the problem is difficult, your program will likely become a long list of complex
rules—pretty hard to maintain.

In contrast, a spam filter based on Machine Learning techniques automatically learns
which  words  and  phrases  are  good  predictors  of  spam  by  detecting  unusually  fre‐
quent  patterns  of  words  in  the  spam  examples  compared  to  the  ham  examples
(Figure 1-2). The program is much shorter, easier to maintain, and most likely more
accurate.

What  if  spammers  notice  that  all  their  emails  containing  “4U”  are  blocked?  They
might  start  writing  “For  U”  instead.  A  spam  filter  using  traditional  programming
techniques would need to be updated to flag “For U” emails. If spammers keep work‐
ing around your spam filter, you will need to keep writing new rules forever.

In contrast, a spam filter based on Machine Learning techniques automatically noti‐
ces that “For U” has become unusually frequent in spam flagged by users, and it starts
flagging them without your intervention (Figure 1-3).

Why Use Machine Learning? 

| 

3

Figure 1-2. The Machine Learning approach

Figure 1-3. Automatically adapting to change

Another area where Machine Learning shines is for problems that either are too com‐
plex for traditional approaches or have no known algorithm. For example, consider
speech recognition. Say you want to start simple and write a program capable of dis‐
tinguishing  the  words  “one”  and  “two.”  You  might  notice  that  the  word  “two”  starts
with  a  high-pitch  sound  (“T”),  so  you  could  hardcode  an  algorithm  that  measures
high-pitch sound intensity and use that to distinguish ones and twos—but obviously
this technique will not scale to thousands of words spoken by millions of very differ‐
ent people in noisy environments and in dozens of languages. The best solution (at
least today) is to write an algorithm that learns by itself, given many example record‐
ings for each word.

Finally, Machine Learning can help humans learn (Figure 1-4). ML algorithms can be
inspected  to  see  what  they  have  learned  (although  for  some  algorithms  this  can  be
tricky).  For  instance,  once  a  spam  filter  has  been  trained  on  enough  spam,  it  can
easily  be  inspected  to  reveal  the  list  of  words  and  combinations  of  words  that  it
believes  are  the  best  predictors  of  spam.  Sometimes  this  will  reveal  unsuspected

4 

| 

Chapter 1: The Machine Learning Landscape

correlations or new trends, and thereby lead to a better understanding of the prob‐
lem. Applying ML techniques to dig into large amounts of data can help discover pat‐
terns that were not immediately apparent. This is called data mining.

Figure 1-4. Machine Learning can help humans learn

To summarize, Machine Learning is great for:

• Problems for which existing solutions require a lot of fine-tuning or long lists of
rules: one Machine Learning algorithm can often simplify code and perform bet‐
ter than the traditional approach.

• Complex problems for which using a traditional approach yields no good solu‐

tion: the best Machine Learning techniques can perhaps find a solution.

• Fluctuating environments: a Machine Learning system can adapt to new data.

• Getting insights about complex problems and large amounts of data.

Examples of Applications
Let’s look at some concrete examples of Machine Learning tasks, along with the tech‐
niques that can tackle them:

Analyzing images of products on a production line to automatically classify them

This is image classification, typically performed using convolutional neural net‐
works (CNNs; see Chapter 14).

Examples of Applications 

| 

5

Detecting tumors in brain scans

This is semantic segmentation, where each pixel in the image is classified (as we
want to determine the exact location and shape of tumors), typically using CNNs
as well.

Automatically classifying news articles

This is natural language processing (NLP), and more specifically text classifica‐
tion,  which  can  be  tackled  using  recurrent  neural  networks  (RNNs),  CNNs,  or
Transformers (see Chapter 16).

Automatically flagging offensive comments on discussion forums
This is also text classification, using the same NLP tools.

Summarizing long documents automatically

This is a branch of NLP called text summarization, again using the same tools.

Creating a chatbot or a personal assistant

This involves many NLP components, including natural language understanding
(NLU) and question-answering modules.

Forecasting your company’s revenue next year, based on many performance metrics

This  is  a  regression  task  (i.e.,  predicting  values)  that  may  be  tackled  using  any
regression model, such as a Linear Regression or Polynomial Regression model
(see Chapter 4), a regression SVM (see Chapter 5), a regression Random Forest
(see Chapter 7), or an artificial neural network (see Chapter 10). If you want to
take  into  account  sequences  of  past  performance  metrics,  you  may  want  to  use
RNNs, CNNs, or Transformers (see Chapters 15 and 16).

Making your app react to voice commands

This is speech recognition, which requires processing audio samples: since they
are long and complex sequences, they are typically processed using RNNs, CNNs,
or Transformers (see Chapters 15 and 16).

Detecting credit card fraud

This is anomaly detection (see Chapter 9).

Segmenting clients based on their purchases so that you can design a different marketing
strategy for each segment

This is clustering (see Chapter 9).

Representing a complex, high-dimensional dataset in a clear and insightful diagram

This  is  data  visualization,  often  involving  dimensionality  reduction  techniques
(see Chapter 8).

Recommending a product that a client may be interested in, based on past purchases

This  is  a  recommender  system.  One  approach  is  to  feed  past  purchases  (and
other  information  about  the  client)  to  an  artificial  neural  network  (see  Chap‐

6 

| 

Chapter 1: The Machine Learning Landscape

ter 10), and get it to output the most likely next purchase. This neural net would
typically be trained on past sequences of purchases across all clients.

Building an intelligent bot for a game

This is often tackled using Reinforcement Learning (RL; see Chapter 18), which
is  a  branch  of  Machine  Learning  that  trains  agents  (such  as  bots)  to  pick  the
actions that will maximize their rewards over time (e.g., a bot may get a reward
every time the player loses some life points), within a given environment (such as
the  game).  The  famous  AlphaGo  program  that  beat  the  world  champion  at  the
game of Go was built using RL.

This  list  could  go  on  and  on,  but  hopefully  it  gives  you  a  sense  of  the  incredible
breadth and complexity of the tasks that Machine Learning can tackle, and the types
of techniques that you would use for each task.

Types of Machine Learning Systems
There  are  so  many  different  types  of  Machine  Learning  systems  that  it  is  useful  to
classify them in broad categories, based on the following criteria:

• Whether or not they are trained with human supervision (supervised, unsuper‐

vised, semisupervised, and Reinforcement Learning)

• Whether  or  not  they  can  learn  incrementally  on  the  fly  (online  versus  batch

learning)

• Whether they work by simply comparing new data points to known data points,
or  instead  by  detecting  patterns  in  the  training  data  and  building  a  predictive
model, much like scientists do (instance-based versus model-based learning)

These  criteria  are  not  exclusive;  you  can  combine  them  in  any  way  you  like.  For
example, a state-of-the-art spam filter may learn on the fly using a deep neural net‐
work model trained using examples of spam and ham; this makes it an online, model-
based, supervised learning system.

Let’s look at each of these criteria a bit more closely.

Supervised/Unsupervised Learning
Machine  Learning  systems  can  be  classified  according  to  the  amount  and  type  of
supervision  they  get  during  training.  There  are  four  major  categories:  supervised
learning,  unsupervised 
learning,  and  Reinforcement
Learning.

learning,  semisupervised 

Types of Machine Learning Systems 

| 

7

Supervised learning

In supervised learning, the training set you feed to the algorithm includes the desired
solutions, called labels (Figure 1-5).

Figure 1-5. A labeled training set for spam classification (an example of supervised
learning)

A typical supervised learning task is classification. The spam filter is a good example
of this: it is trained with many example emails along with their class (spam or ham),
and it must learn how to classify new emails.

Another  typical  task  is  to  predict  a  target  numeric  value,  such  as  the  price  of  a  car,
given a set of features (mileage, age, brand, etc.) called predictors. This sort of task is
called regression (Figure 1-6).1 To train the system, you need to give it many examples
of cars, including both their predictors and their labels (i.e., their prices).

In  Machine  Learning  an  attribute  is  a  data  type  (e.g.,  “mileage”),
while a feature has several meanings, depending on the context, but
generally  means  an  attribute  plus  its  value  (e.g.,  “mileage  =
15,000”).  Many  people  use  the  words  attribute  and  feature  inter‐
changeably.

Note that some regression algorithms can be used for classification as well, and vice
versa. For example, Logistic Regression is commonly used for classification, as it can
output a value that corresponds to the probability of belonging to a given class (e.g.,
20% chance of being spam).

1 Fun fact: this odd-sounding name is a statistics term introduced by Francis Galton while he was studying the
fact that the children of tall people tend to be shorter than their parents. Since the children were shorter, he
called this regression to the mean. This name was then applied to the methods he used to analyze correlations
between variables.

8 

| 

Chapter 1: The Machine Learning Landscape

Figure 1-6. A regression problem: predict a value, given an input feature (there are usu‐
ally multiple input features, and sometimes multiple output values)

Here are some of the most important supervised learning algorithms (covered in this
book):

• k-Nearest Neighbors

• Linear Regression

• Logistic Regression

• Support Vector Machines (SVMs)

• Decision Trees and Random Forests
• Neural networks2

Unsupervised learning

In  unsupervised  learning,  as  you  might  guess,  the  training  data  is  unlabeled
(Figure 1-7). The system tries to learn without a teacher.

2 Some neural network architectures can be unsupervised, such as autoencode