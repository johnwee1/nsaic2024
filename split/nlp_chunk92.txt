... Washington rejected the bid ...
(22.83) I once crossed that border into Ashgh-Abad on Nowruz, the Persian New

Year. In the South, everyone was celebrating New Year; to the North, it
was a regular day.

(22.84) In France, the president is elected for a term of seven years, while in the

United States he is elected for a term of four years.

For further linguistic discussions of these complications of coreference see Puste-
jovsky (1991), van Deemter and Kibble (2000), Poesio et al. (2006), Fauconnier and
Turner (2008), Versley (2008), and Barker (2010).

Ng (2017) offers a useful compact history of machine learning models in coref-
erence resolution. There are three excellent book-length surveys of anaphora/coref-
erence resolution, covering different time periods: Hirst (1981) (early work until
about 1981), Mitkov (2002) (1986-2001), and Poesio et al. (2016) (2001-2015).

Andy Kehler wrote the Discourse chapter for the 2000 ﬁrst edition of this text-
book, which we used as the starting point for the second-edition chapter, and there
are some remnants of Andy’s lovely prose still in this third-edition coreference chap-
ter.

metonymy

Exercises

CHAPTER

23 Discourse Coherence

And even in our wildest and most wandering reveries, nay in our very dreams,
we shall ﬁnd, if we reﬂect, that the imagination ran not altogether at adven-
tures, but that there was still a connection upheld among the different ideas,
which succeeded each other. Were the loosest and freest conversation to be
transcribed, there would immediately be transcribed, there would immediately
be observed something which connected it in all its transitions.

David Hume, An enquiry concerning human understanding, 1748

Orson Welles’ movie Citizen Kane was groundbreaking in many ways, perhaps most
notably in its structure. The story of the life of ﬁctional media magnate Charles
Foster Kane, the movie does not proceed in chronological order through Kane’s
life. Instead, the ﬁlm begins with Kane’s death (famously murmuring “Rosebud”)
and is structured around ﬂashbacks to his life inserted among scenes of a reporter
investigating his death. The novel idea that the structure of a movie does not have
to linearly follow the structure of the real timeline made apparent for 20th century
cinematography the inﬁnite possibilities and impact of different kinds of coherent
narrative structures.

But coherent structure is not just a fact about movies or works of art. Like
movies, language does not normally consist of isolated, unrelated sentences, but
instead of collocated, structured, coherent groups of sentences. We refer to such
a coherent structured group of sentences as a discourse, and we use the word co-
herence to refer to the relationship between sentences that makes real discourses
different than just random assemblages of sentences. The chapter you are now read-
ing is an example of a discourse, as is a news article, a conversation, a thread on
social media, a Wikipedia page, and your favorite novel.

What makes a discourse coherent? If you created a text by taking random sen-
tences each from many different sources and pasted them together, would that be a
coherent discourse? Almost certainly not. Real discourses exhibit both local coher-
ence and global coherence. Let’s consider three ways in which real discourses are
locally coherent;

First, sentences or clauses in real discourses are related to nearby sentences in

systematic ways. Consider this example from Hobbs (1979):

(23.1)

John took a train from Paris to Istanbul. He likes spinach.

This sequence is incoherent because it is unclear to a reader why the second
sentence follows the ﬁrst; what does liking spinach have to do with train trips? In
fact, a reader might go to some effort to try to ﬁgure out how the discourse could be
coherent; perhaps there is a French spinach shortage? The very fact that hearers try
to identify such connections suggests that human discourse comprehension involves
the need to establish this kind of coherence.

By contrast, in the following coherent example:

(23.2)

Jane took a train from Paris to Istanbul. She had to attend a conference.

discourse

coherence

local

global

512 CHAPTER 23

• DISCOURSE COHERENCE

coherence
relations

the second sentence gives a REASON for Jane’s action in the ﬁrst sentence. Struc-
tured relationships like REASON that hold between text units are called coherence
relations, and coherent discourses are structured by many such coherence relations.
Coherence relations are introduced in Section 23.1.

A second way a discourse can be locally coherent is by virtue of being “about”
someone or something. In a coherent discourse some entities are salient, and the
discourse focuses on them and doesn’t go back and forth between multiple entities.
This is called entity-based coherence. Consider the following incoherent passage,
in which the salient entity seems to wildly swing from John to Jenny to the piano
store to the living room, back to Jenny, then the piano again:

Centering
Theory

entity grid

topically
coherent

lexical cohesion

(23.3)

John wanted to buy a piano for his living room.
Jenny also wanted to buy a piano.
He went to the piano store.
It was nearby.
The living room was on the second ﬂoor.
She didn’t ﬁnd anything she liked.
The piano he bought was hard to get up to that ﬂoor.

Entity-based coherence models measure this kind of coherence by tracking salient
entities across a discourse. For example Centering Theory (Grosz et al., 1995), the
most inﬂuential theory of entity-based coherence, keeps track of which entities in
the discourse model are salient at any point (salient entities are more likely to be
pronominalized or to appear in prominent syntactic positions like subject or object).
In Centering Theory, transitions between sentences that maintain the same salient
entity are considered more coherent than ones that repeatedly shift between entities.
The entity grid model of coherence (Barzilay and Lapata, 2008) is a commonly
used model that realizes some of the intuitions of the Centering Theory framework.
Entity-based coherence is introduced in Section 23.3.

Finally, discourses can be locally coherent by being topically coherent: nearby
sentences are generally about the same topic and use the same or similar vocab-
ulary to discuss these topics. Because topically coherent discourses draw from a
single semantic ﬁeld or topic, they tend to exhibit the surface property known as
lexical cohesion (Halliday and Hasan, 1976): the sharing of identical or semanti-
cally related words in nearby sentences. For example, the fact that the words house,
chimney, garret, closet, and window— all of which belong to the same semantic
ﬁeld— appear in the two sentences in (23.4), or that they share the identical word
shingled, is a cue that the two are tied together as a discourse:

(23.4) Before winter I built a chimney, and shingled the sides of my house...
I have thus a tight shingled and plastered house... with a garret and a

closet, a large window on each side....

In addition to the local coherence between adjacent or nearby sentences, dis-
courses also exhibit global coherence. Many genres of text are associated with
particular conventional discourse structures. Academic articles might have sections
describing the Methodology or Results. Stories might follow conventional plotlines
or motifs. Persuasive essays have a particular claim they are trying to argue for,
and an essay might express this claim together with a structured set of premises that
support the argument and demolish potential counterarguments. We’ll introduce
versions of each of these kinds of global coherence.

Why do we care about the local or global coherence of a discourse? Since co-
herence is a property of a well-written text, coherence detection plays a part in any

23.1

• COHERENCE RELATIONS

513

task that requires measuring the quality of a text. For example coherence can help
in pedagogical tasks like essay grading or essay quality measurement that are trying
to grade how well-written a human essay is (Somasundaran et al. 2014, Feng et al.
2014, Lai and Tetreault 2018). Coherence can also help for summarization; knowing
the coherence relationship between sentences can help know how to select informa-
tion from them. Finally, detecting incoherent text may even play a role in mental
health tasks like measuring symptoms of schizophrenia or other kinds of disordered
language (Ditman and Kuperberg 2010, Elvev˚ag et al. 2007, Bedi et al. 2015, Iter
et al. 2018).

23.1 Coherence Relations

coherence
relation

RST

nucleus

satellite

Recall from the introduction the difference between passages (23.5) and (23.6).

(23.5) Jane took a train from Paris to Istanbul. She likes spinach.
(23.6) Jane took a train from Paris to Istanbul. She had to attend a conference.

The reason (23.6) is more coherent is that the reader can form a connection be-
tween the two sentences, in which the second sentence provides a potential REASON
for the ﬁrst sentences. This link is harder to form for (23.5). These connections
between text spans in a discourse can be speciﬁed as a set of coherence relations.
The next two sections describe two commonly used models of coherence relations
and associated corpora: Rhetorical Structure Theory (RST), and the Penn Discourse
TreeBank (PDTB).

23.1.1 Rhetorical Structure Theory

The most commonly used model of discourse organization is Rhetorical Structure
Theory (RST) (Mann and Thompson, 1987). In RST relations are deﬁned between
two spans of text, generally a nucleus and a satellite. The nucleus is the unit that
is more central to the writer’s purpose and that is interpretable independently; the
satellite is less central and generally is only interpretable with respect to the nucleus.
Some symmetric relations, however, hold between two nuclei.

Below are a few examples of RST coherence relations, with deﬁnitions adapted

from the RST Treebank Manual (Carlson and Marcu, 2001).

Reason: The nucleus is an action carried out by an animate agent and the satellite
is the reason for the nucleus.

(23.7) [NUC Jane took a train from Paris to Istanbul.] [SAT She had to attend a

conference.]

Elaboration: The satellite gives additional information or detail about the situation
presented in the nucleus.

(23.8) [NUC Dorothy was from Kansas.] [SAT She lived in the midst of the great

Kansas prairies.]

Evidence: The satellite gives additional information or detail about the situation
presented in the nucleus. The information is presented with the goal of convince the
reader to accept the information presented in the nucleus.

(23.9) [NUC Kevin must be here.] [SAT His car is parked outside.]

514 CHAPTER 23

• DISCOURSE COHERENCE

Attribution: The satellite gives the source of attribution for an instance of reported
speech in the nucleus.

(23.10) [SAT Analysts estimated] [NUC that sales at U.S. stores declined in the

quarter, too]

List: In this multinuclear relation, a series of nuclei is given, without contrast or
explicit comparison:

(23.11) [NUC Billy Bones was the mate; ] [NUC Long John, he was quartermaster]

RST relations are traditionally represented graphically; the asymmetric Nucleus-

Satellite relation is represented with an arrow from the satellite to the nucleus:

We can also talk about the coherence of a larger text by considering the hierar-
chical structure between coherence relations. Figure 23.1 shows the rhetorical struc-
ture of a paragraph from Marcu (2000a) for the text in (23.12) from the Scientiﬁc
American magazine.

(23.12) With its distant orbit–50 percent farther from the sun than Earth–and slim

atmospheric blanket, Mars experiences frigid weather conditions. Surface
temperatures typically average about -60 degrees Celsius (-76 degrees
Fahrenheit) at the equator and can dip to -123 degrees C near the poles. Only
the midday sun at tropical latitudes is warm enough to thaw ice on occasion,
but any liquid water formed in this way would evaporate almost instantly
because of the low atmospheric pressure.

Figure 23.1 A discourse tree for the Scientiﬁc American text in (23.12), from Marcu (2000a). Note that
asymmetric relations are represented with a curved arrow from the satellite to the nucleus.

EDU

The leaves in the Fig. 23.1 tree correspond to text spans of a sentence, clause or
phrase that are called elementary discourse units or EDUs in RST; these units can
also be referred to as discourse segments. Because these units may correspond to
arbitrary spans of text, determining the boundaries of an EDU is an important task
for extracting coherence relations. Roughly speaking, one can think of discourse

Kevin must be here.His car is parked outsideevidenceTitle(1)Mars2-9evidence2-3background  (2)WIth its distant orbit  <p> -- 50 percent farther from the sun than Earth -- </p> and slim atmospheric blanket,(3)Marsexperiencesfrigid weatherconditions.4-9elaboration-additional(4)Surface temperatures typically average about -60 degrees Celsius <p> (-76 degreesFahrenheit)</p> at the equator4-5List(5)and can dipto -123degrees Cnear thepoles.6-9Contrast6-7(6)Only themidday sun attropical latitudesis warm enough(7)to thaw iceon occasion,purpose8-9explanation-argumentative(8)but any liquid waterformed in this way would evaporate almost instantly(9)because ofthe lowatmosphericpressure.PDTB

discourse
connectives

23.1

• COHERENCE RELATIONS

515

segments as being analogous to constituents in sentence syntax, and indeed as we’ll
see in Section 23.2 we generally draw on parsing algorithms to infer discourse struc-
ture.

There are corpora for many discourse coherence models; the RST Discourse
TreeBank (Carlson et al., 2001) is the largest available discourse corpus. It con-
sists of 385 English language documents selected from the Penn Treebank, with full
RST parses for each one, using a large set of 78 distinct relations, grouped into 16
classes. RST treebanks exist also for Spanish, German, Basque, Dutch and Brazilian
Portuguese (Braud et al., 2017).

Now that we’ve seen examples of coherence, we can see more clearly how a
coherence relation can play a role in summarization or information extraction. For
example, the nuclei of a text presumably express more important information than
the satellites, which might be dropped in a summary.

23.1.2 Penn Discourse TreeBank (PDTB)

The Penn Discourse TreeBank (PDTB) is a second commonly used dataset that
embodies another model of coherence relations (Miltsakaki et al. 2004, Prasad et al.
2008, Prasad et al. 2014). PDTB labeling is lexically grounded. Instead of asking
annotators to directly tag the coherence relation between text spans, they were given
a list of discourse connectives, words that signal discourse relations, like because,
although, when, since, or as a result. In a part of a text where these words marked a
coherence relation between two text spans, the connective and the spans were then
annotated, as in Fig. 23.13, where the phrase as a result signals a causal relationship
between what PDTB calls Arg1 (the ﬁrst two sentences, here in italics) and Arg2
(the third sentence, here in bold).

(23.13) Jewelry displays in department stores were often cluttered and uninspired.
And the merchandise was, well, fake. As a result, marketers of faux gems
steadily lost space in department stores to more fashionable
rivals—cosmetics makers.

(23.14) In July, the Environmental Protection Agency 