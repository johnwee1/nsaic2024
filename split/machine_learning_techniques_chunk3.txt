ns?

Figure 1-22. Overfitting the training data

Main Challenges of Machine Learning 

| 

27

Complex models such as deep neural networks can detect subtle patterns in the data,
but if the training set is noisy, or if it is too small (which introduces sampling noise),
then the model is likely to detect patterns in the noise itself. Obviously these patterns
will not generalize to new instances. For example, say you feed your life satisfaction
model  many  more  attributes,  including  uninformative  ones  such  as  the  country’s
name. In that case, a complex model may detect patterns like the fact that all coun‐
tries in the training data with a w in their name have a life satisfaction greater than 7:
New Zealand (7.3), Norway (7.4), Sweden (7.2), and Switzerland (7.5). How confident
are you that the w-satisfaction rule generalizes to Rwanda or Zimbabwe? Obviously
this pattern occurred in the training data by pure chance, but the model has no way
to tell whether a pattern is real or simply the result of noise in the data.

Overfitting happens when the model is too complex relative to the
amount and noisiness of the training data. Here are possible solu‐
tions:

• Simplify  the  model  by  selecting  one  with  fewer  parameters
(e.g.,  a  linear  model  rather  than  a  high-degree  polynomial
model),  by  reducing  the  number  of  attributes  in  the  training
data, or by constraining the model.

• Gather more training data.

• Reduce the noise in the training data (e.g., fix data errors and

remove outliers).

Constraining a model to make it simpler and reduce the risk of overfitting is called
regularization. For example, the linear model we defined earlier has two parameters,
θ0 and θ1. This gives the learning algorithm two degrees of freedom to adapt the model
to the training data: it can tweak both the height (θ0) and the slope (θ1) of the line. If
we forced θ1 = 0, the algorithm would have only one degree of freedom and would
have a much harder time fitting the data properly: all it could do is move the line up
or  down  to  get  as  close  as  possible  to  the  training  instances,  so  it  would  end  up
around the mean. A very simple model indeed! If we allow the algorithm to modify θ1
but we force it to keep it small, then the learning algorithm will effectively have some‐
where in between one and two degrees of freedom. It will produce a model that’s sim‐
pler than one with two degrees of freedom, but more complex than one with just one.
You  want  to  find  the  right  balance  between  fitting  the  training  data  perfectly  and
keeping the model simple enough to ensure that it will generalize well.

Figure  1-23  shows  three  models.  The  dotted  line  represents  the  original  model  that
was trained on the countries represented as circles (without the countries represented
as squares), the dashed line is our second model trained with all countries (circles and
squares), and the solid line is a model trained with the same data as the first model

28 

| 

Chapter 1: The Machine Learning Landscape

but with a regularization constraint. You can see that regularization forced the model
to have a smaller slope: this model does not fit the training data (circles) as well as the
first model, but it actually generalizes better to new examples that it did not see dur‐
ing training (squares).

Figure 1-23. Regularization reduces the risk of overfitting

The amount of regularization to apply during learning can be controlled by a hyper‐
parameter.  A  hyperparameter  is  a  parameter  of  a  learning  algorithm  (not  of  the
model). As such, it is not affected by the learning algorithm itself; it must be set prior
to training and remains constant during training. If you set the regularization hyper‐
parameter  to  a  very  large  value,  you  will  get  an  almost  flat  model  (a  slope  close  to
zero); the learning algorithm will almost certainly not overfit the training data, but it
will  be  less  likely  to  find  a  good  solution.  Tuning  hyperparameters  is  an  important
part  of  building  a  Machine  Learning  system  (you  will  see  a  detailed  example  in  the
next chapter).

Underfitting the Training Data
As  you  might  guess,  underfitting  is  the  opposite  of  overfitting:  it  occurs  when  your
model is too simple to learn the underlying structure of the data. For example, a lin‐
ear  model  of  life  satisfaction  is  prone  to  underfit;  reality  is  just  more  complex  than
the  model,  so  its  predictions  are  bound  to  be  inaccurate,  even  on  the  training
examples.

Here are the main options for fixing this problem:

• Select a more powerful model, with more parameters.

• Feed better features to the learning algorithm (feature engineering).

• Reduce the constraints on the model (e.g., reduce the regularization hyperpara‐

meter).

Main Challenges of Machine Learning 

| 

29

Stepping Back
By now you know a lot about Machine Learning. However, we went through so many
concepts  that  you  may  be  feeling  a  little  lost,  so  let’s  step  back  and  look  at  the  big
picture:

• Machine Learning is about making machines get better at some task by learning

from data, instead of having to explicitly code rules.

• There are many different types of ML systems: supervised or not, batch or online,

instance-based or model-based.

• In an ML project you gather data in a training set, and you feed the training set to
a learning algorithm. If the algorithm is model-based, it tunes some parameters
to fit the model to the training set (i.e., to make good predictions on the training
set  itself),  and  then  hopefully  it  will  be  able  to  make  good  predictions  on  new
cases  as  well.  If  the  algorithm  is  instance-based,  it  just  learns  the  examples  by
heart and generalizes to new instances by using a similarity measure to compare
them to the learned instances.

• The system will not perform well if your training set is too small, or if the data is
not  representative,  is  noisy,  or  is  polluted  with  irrelevant  features  (garbage  in,
garbage out). Lastly, your model needs to be neither too simple (in which case it
will underfit) nor too complex (in which case it will overfit).

There’s  just  one  last  important  topic  to  cover:  once  you  have  trained  a  model,  you
don’t want to just “hope” it generalizes to new cases. You want to evaluate it and fine-
tune it if necessary. Let’s see how to do that.

Testing and Validating
The only way to know how well a model will generalize to new cases is to actually try
it out on new cases. One way to do that is to put your model in production and moni‐
tor  how  well  it  performs.  This  works  well,  but  if  your  model  is  horribly  bad,  your
users will complain—not the best idea.

A better option is to split your data into two sets: the training set and the test set. As
these names imply, you train your model using the training set, and you test it using
the test set. The error rate on new cases is called the generalization error (or out-of-
sample error), and by evaluating your model on the test set, you get an estimate of this
error. This value tells you how well your model will perform on instances it has never
seen before.

If the training error is low (i.e., your model makes few mistakes on the training set)
but the generalization error is high, it means that your model is overfitting the train‐
ing data.

30 

| 

Chapter 1: The Machine Learning Landscape

It is common to use 80% of the data for training and hold out 20%
for  testing.  However,  this  depends  on  the  size  of  the  dataset:  if  it
contains 10 million instances, then holding out 1% means your test
set  will  contain  100,000  instances,  probably  more  than  enough  to
get a good estimate of the generalization error.

Hyperparameter Tuning and Model Selection
Evaluating a model is simple enough: just use a test set. But suppose you are hesitat‐
ing between two types of models (say, a linear model and a polynomial model): how
can  you  decide  between  them?  One  option  is  to  train  both  and  compare  how  well
they generalize using the test set.

Now  suppose  that  the  linear  model  generalizes  better,  but  you  want  to  apply  some
regularization to avoid overfitting. The question is, how do you choose the value of
the regularization hyperparameter? One option is to train 100 different models using
100 different values for this hyperparameter. Suppose you find the best hyperparame‐
ter  value  that  produces  a  model  with  the  lowest  generalization  error—say,  just  5%
error. You launch this model into production, but unfortunately it does not perform
as well as expected and produces 15% errors. What just happened?

The problem is that you measured the generalization error multiple times on the test
set, and you adapted the model and hyperparameters to produce the best model for
that particular set. This means that the model is unlikely to perform as well on new
data.

A common solution to this problem is called holdout validation: you simply hold out
part of the training set to evaluate several candidate models and select the best one.
The new held-out set is called the validation set (or sometimes the development set, or
dev  set).  More  specifically,  you  train  multiple  models  with  various  hyperparameters
on  the  reduced  training  set  (i.e.,  the  full  training  set  minus  the  validation  set),  and
you select the model that performs best on the validation set. After this holdout vali‐
dation process, you train the best model on the full training set (including the valida‐
tion set), and this gives you the final model. Lastly, you evaluate this final model on
the test set to get an estimate of the generalization error.

This solution usually works quite well. However, if the validation set is too small, then
model evaluations will be imprecise: you may end up selecting a suboptimal model by
mistake. Conversely, if the validation set is too large, then the remaining training set
will be much smaller than the full training set. Why is this bad? Well, since the final
model  will  be  trained  on  the  full  training  set,  it  is  not  ideal  to  compare  candidate
models trained on a much smaller training set. It would be like selecting the fastest
sprinter  to  participate  in  a  marathon.  One  way  to  solve  this  problem  is  to  perform
repeated  cross-validation,  using  many  small  validation  sets.  Each  model  is  evaluated
once per validation set after it is trained on the rest of the data. By averaging out all

Testing and Validating 

| 

31

the  evaluations  of  a  model,  you  get  a  much  more  accurate  measure  of  its  perfor‐
mance. There is a drawback, however: the training time is multiplied by the number
of validation sets.

Data Mismatch
In some cases, it’s easy to get a large amount of data for training, but this data proba‐
bly won’t be perfectly representative of the data that will be used in production. For
example,  suppose  you  want  to  create  a  mobile  app  to  take  pictures  of  flowers  and
automatically determine their species. You can easily download millions of pictures of
flowers on the web, but they won’t be perfectly representative of the pictures that will
actually be taken using the app on a mobile device. Perhaps you only have 10,000 rep‐
resentative pictures (i.e., actually taken with the app). In this case, the most important
rule to remember is that the validation set and the test set must be as representative as
possible  of  the  data  you  expect  to  use  in  production,  so  they  should  be  composed
exclusively of representative pictures: you can shuffle them and put half in the valida‐
tion set and half in the test set (making sure that no duplicates or near-duplicates end
up  in  both  sets).  But  after  training  your  model  on  the  web  pictures,  if  you  observe
that the performance of the model on the validation set is disappointing, you will not
know whether this is because your model has overfit the training set, or whether this
is  just  due  to  the  mismatch  between  the  web  pictures  and  the  mobile  app  pictures.
One  solution  is  to  hold  out  some  of  the  training  pictures  (from  the  web)  in  yet
another set that Andrew Ng calls the train-dev set. After the model is trained (on the
training  set,  not  on  the  train-dev  set),  you  can  evaluate  it  on  the  train-dev  set.  If  it
performs well, then the model is not overfitting the training set. If it performs poorly
on the validation set, the problem must be coming from the data mismatch. You can
try to tackle this problem by preprocessing the web images to make them look more
like the pictures that will be taken by the mobile app, and then retraining the model.
Conversely, if the model performs poorly on the train-dev set, then it must have over‐
fit  the  training  set,  so  you  should  try  to  simplify  or  regularize  the  model,  get  more
training data, and clean up the training data.

32 

| 

Chapter 1: The Machine Learning Landscape

No Free Lunch Theorem
A model is a simplified version of the observations. The simplifications are meant to
discard  the  superfluous  details  that  are  unlikely  to  generalize  to  new  instances.  To
decide what data to discard and what data to keep, you must make assumptions. For
example, a linear model makes the assumption that the data is fundamentally linear
and that the distance between the instances and the straight line is just noise, which
can safely be ignored.

In  a  famous  1996  paper,11  David  Wolpert  demonstrated  that  if  you  make  absolutely
no assumption about the data, then there is no reason to prefer one model over any
other.  This  is  called  the  No  Free  Lunch  (NFL)  theorem.  For  some  datasets  the  best
model is a linear model, while for other datasets it is a neural network. There is no
model that is a priori guaranteed to work better (hence the name of the theorem). The
only way to know for sure which model is best is to evaluate them all. Since this is not
possible, in practice you make some reasonable assumptions about the data and eval‐
uate  only  a  few  reasonable  models.  For  example,  for  simple  tasks  you  may  evaluate
linear  models  with  various  levels  of  regularization,  and  for  a  complex  problem  you
may evaluate various neural networks.

Exercises
In  this  chapter  we  have  covered  some  of  the  most  important  concepts  in  Machine
Learning. In the next chapters we will dive deeper and write more code, but before we
do, make sure you know how to answer the following questions:

1. How would you define Machine Learning?

2. Can you name four types of problems where it shines?

3. What is a labeled training set?

4. What are the two most common supervised tasks?

5. Can you name four common unsupervised tasks?

6. What  type  of  Machine  Learning  algorithm  would  you  use  to  allow  a  robot  to

walk in various unknown terrains?

7. What type of algorithm would you use to segment your customers into multiple

groups?

8. Would you frame the problem of spam detection as a supervised learning prob‐

lem or an unsupervised learning problem?

11 David Wolpert, “The Lack of A Priori Distinctions Between Learning Algorithms,” Neural Computation 8, no.

7 (1996): 1341–1390.

Exercises 

| 

33

9. What is an online le